{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COUNTRY_NAME</th>\n",
       "      <th>ISO2</th>\n",
       "      <th>ADMIN1</th>\n",
       "      <th>ADMIN2</th>\n",
       "      <th>SITE_NAME</th>\n",
       "      <th>SITE_CODE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>TEST_TYPE</th>\n",
       "      <th>YEAR_START</th>\n",
       "      <th>VECTOR SPECIES</th>\n",
       "      <th>STAGE_ORIGIN</th>\n",
       "      <th>MOSQUITO_NUMBER</th>\n",
       "      <th>MECHANISM_STATUS</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "      <th>CITATION</th>\n",
       "      <th>CITATION_URL</th>\n",
       "      <th>DATA_CURATOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IR000000622</td>\n",
       "      <td>Benin</td>\n",
       "      <td>BJ</td>\n",
       "      <td>Outmt</td>\n",
       "      <td>Adjarra</td>\n",
       "      <td>Adjarra</td>\n",
       "      <td>IRBJ3</td>\n",
       "      <td>6.5333</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>kdr L1014F</td>\n",
       "      <td>2010</td>\n",
       "      <td>An. gambiae s.l.</td>\n",
       "      <td>F0_ADULTS_(FROM_WILD_LARVAE)</td>\n",
       "      <td>27</td>\n",
       "      <td>Detected</td>\n",
       "      <td>Centre de Recherches Entomologiques de Cotonou</td>\n",
       "      <td>Aizoun et al. (2013) Comparison of the standar...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/23688233</td>\n",
       "      <td>World Health Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IR000000623</td>\n",
       "      <td>Benin</td>\n",
       "      <td>BJ</td>\n",
       "      <td>Outmt</td>\n",
       "      <td>Adjarra</td>\n",
       "      <td>Adjarra</td>\n",
       "      <td>IRBJ3</td>\n",
       "      <td>6.5333</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>Ace1R</td>\n",
       "      <td>2010</td>\n",
       "      <td>An. gambiae s.l.</td>\n",
       "      <td>F0_ADULTS_(FROM_WILD_LARVAE)</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not detected</td>\n",
       "      <td>Centre de Recherches Entomologiques de Cotonou</td>\n",
       "      <td>Aizoun et al. (2013) Comparison of the standar...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/23688233</td>\n",
       "      <td>World Health Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IR000000632</td>\n",
       "      <td>Benin</td>\n",
       "      <td>BJ</td>\n",
       "      <td>Outmt</td>\n",
       "      <td>Adjohoun</td>\n",
       "      <td>Adjohoun</td>\n",
       "      <td>IRBJ5</td>\n",
       "      <td>6.7072</td>\n",
       "      <td>2.4964</td>\n",
       "      <td>kdr L1014F</td>\n",
       "      <td>2010</td>\n",
       "      <td>An. coluzzii</td>\n",
       "      <td>NR</td>\n",
       "      <td>24</td>\n",
       "      <td>Detected</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Padonou et al. (2012) Impact of three years of...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/22490146</td>\n",
       "      <td>World Health Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IR000000634</td>\n",
       "      <td>Benin</td>\n",
       "      <td>BJ</td>\n",
       "      <td>Outmt</td>\n",
       "      <td>Adjohoun</td>\n",
       "      <td>Adjohoun</td>\n",
       "      <td>IRBJ5</td>\n",
       "      <td>6.7072</td>\n",
       "      <td>2.4964</td>\n",
       "      <td>Ace1R</td>\n",
       "      <td>2010</td>\n",
       "      <td>An. coluzzii</td>\n",
       "      <td>NR</td>\n",
       "      <td>24</td>\n",
       "      <td>Not detected</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Padonou et al. (2012) Impact of three years of...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/22490146</td>\n",
       "      <td>World Health Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IR000000644</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>KE</td>\n",
       "      <td>Kisumu County</td>\n",
       "      <td>Nyando</td>\n",
       "      <td>Ahero</td>\n",
       "      <td>IRKE4</td>\n",
       "      <td>-0.1726</td>\n",
       "      <td>34.9198</td>\n",
       "      <td>kdr L1014F</td>\n",
       "      <td>2010</td>\n",
       "      <td>An. arabiensis</td>\n",
       "      <td>NR</td>\n",
       "      <td>100</td>\n",
       "      <td>Not detected</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ochomo et al. (2013) Pyrethroid resistance in ...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/22861380</td>\n",
       "      <td>World Health Organization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID COUNTRY_NAME ISO2         ADMIN1    ADMIN2 SITE_NAME SITE_CODE  \\\n",
       "0  IR000000622        Benin   BJ          Outmt   Adjarra   Adjarra     IRBJ3   \n",
       "1  IR000000623        Benin   BJ          Outmt   Adjarra   Adjarra     IRBJ3   \n",
       "2  IR000000632        Benin   BJ          Outmt  Adjohoun  Adjohoun     IRBJ5   \n",
       "3  IR000000634        Benin   BJ          Outmt  Adjohoun  Adjohoun     IRBJ5   \n",
       "4  IR000000644        Kenya   KE  Kisumu County    Nyando     Ahero     IRKE4   \n",
       "\n",
       "   LATITUDE  LONGITUDE   TEST_TYPE  YEAR_START    VECTOR SPECIES  \\\n",
       "0    6.5333     2.6667  kdr L1014F        2010  An. gambiae s.l.   \n",
       "1    6.5333     2.6667       Ace1R        2010  An. gambiae s.l.   \n",
       "2    6.7072     2.4964  kdr L1014F        2010      An. coluzzii   \n",
       "3    6.7072     2.4964       Ace1R        2010      An. coluzzii   \n",
       "4   -0.1726    34.9198  kdr L1014F        2010    An. arabiensis   \n",
       "\n",
       "                   STAGE_ORIGIN MOSQUITO_NUMBER MECHANISM_STATUS  \\\n",
       "0  F0_ADULTS_(FROM_WILD_LARVAE)              27         Detected   \n",
       "1  F0_ADULTS_(FROM_WILD_LARVAE)   Not available     Not detected   \n",
       "2                            NR              24         Detected   \n",
       "3                            NR              24     Not detected   \n",
       "4                            NR             100     Not detected   \n",
       "\n",
       "                                      DATA_SOURCE  \\\n",
       "0  Centre de Recherches Entomologiques de Cotonou   \n",
       "1  Centre de Recherches Entomologiques de Cotonou   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "\n",
       "                                            CITATION  \\\n",
       "0  Aizoun et al. (2013) Comparison of the standar...   \n",
       "1  Aizoun et al. (2013) Comparison of the standar...   \n",
       "2  Padonou et al. (2012) Impact of three years of...   \n",
       "3  Padonou et al. (2012) Impact of three years of...   \n",
       "4  Ochomo et al. (2013) Pyrethroid resistance in ...   \n",
       "\n",
       "                                   CITATION_URL               DATA_CURATOR  \n",
       "0  https://www.ncbi.nlm.nih.gov/pubmed/23688233  World Health Organization  \n",
       "1  https://www.ncbi.nlm.nih.gov/pubmed/23688233  World Health Organization  \n",
       "2  https://www.ncbi.nlm.nih.gov/pubmed/22490146  World Health Organization  \n",
       "3  https://www.ncbi.nlm.nih.gov/pubmed/22490146  World Health Organization  \n",
       "4  https://www.ncbi.nlm.nih.gov/pubmed/22861380  World Health Organization  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset_path = r'C:\\Users\\rithv\\OneDrive\\Desktop\\cnn_rnn_models\\mosquito_resdev\\mtmbiochemassdata.csv' # Replace with your dataset path\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rithv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('mtmbiochemassdata.csv')\n",
    "\n",
    "# One-hot encoding example\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "encoded_features = ohe.fit_transform(df[['COUNTRY_NAME', 'VECTOR SPECIES']])\n",
    "\n",
    "# Label encoding example\n",
    "le = LabelEncoder()\n",
    "df['ADMIN1'] = le.fit_transform(df['ADMIN1'])\n",
    "\n",
    "# Replace 'Not available' with NaN and convert column to numeric\n",
    "df['MOSQUITO_NUMBER'] = pd.to_numeric(df['MOSQUITO_NUMBER'], errors='coerce')\n",
    "\n",
    "# Impute missing values with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df['MOSQUITO_NUMBER'] = imputer.fit_transform(df[['MOSQUITO_NUMBER']])\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[['LATITUDE', 'LONGITUDE']] = scaler.fit_transform(df[['LATITUDE', 'LONGITUDE']])\n",
    "\n",
    "# Encode target variable\n",
    "df['MECHANISM_STATUS'] = df['MECHANISM_STATUS'].map({'Detected': 1, 'Not detected': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your original DataFrame after applying all preprocessing and feature engineering\n",
    "\n",
    "# Select only the columns you need for modeling\n",
    "modeling_columns = ['COUNTRY_NAME', 'VECTOR SPECIES', 'LATITUDE', 'LONGITUDE', 'YEAR_START', 'MOSQUITO_NUMBER', 'MECHANISM_STATUS']  # Add or remove columns as needed\n",
    "modeling_df = df[modeling_columns]\n",
    "\n",
    "# Save the DataFrame with the selected columns to a new CSV file\n",
    "modeling_df.to_csv('mosquito_modeling_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTRY_NAME</th>\n",
       "      <th>VECTOR SPECIES</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>YEAR_START</th>\n",
       "      <th>MOSQUITO_NUMBER</th>\n",
       "      <th>MECHANISM_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benin</td>\n",
       "      <td>An. gambiae s.l.</td>\n",
       "      <td>-0.210991</td>\n",
       "      <td>-0.409886</td>\n",
       "      <td>2010</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benin</td>\n",
       "      <td>An. gambiae s.l.</td>\n",
       "      <td>-0.210991</td>\n",
       "      <td>-0.409886</td>\n",
       "      <td>2010</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benin</td>\n",
       "      <td>An. coluzzii</td>\n",
       "      <td>-0.191057</td>\n",
       "      <td>-0.414052</td>\n",
       "      <td>2010</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benin</td>\n",
       "      <td>An. coluzzii</td>\n",
       "      <td>-0.191057</td>\n",
       "      <td>-0.414052</td>\n",
       "      <td>2010</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>An. arabiensis</td>\n",
       "      <td>-0.979655</td>\n",
       "      <td>0.379213</td>\n",
       "      <td>2010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  COUNTRY_NAME    VECTOR SPECIES  LATITUDE  LONGITUDE  YEAR_START  \\\n",
       "0        Benin  An. gambiae s.l. -0.210991  -0.409886        2010   \n",
       "1        Benin  An. gambiae s.l. -0.210991  -0.409886        2010   \n",
       "2        Benin      An. coluzzii -0.191057  -0.414052        2010   \n",
       "3        Benin      An. coluzzii -0.191057  -0.414052        2010   \n",
       "4        Kenya    An. arabiensis -0.979655   0.379213        2010   \n",
       "\n",
       "   MOSQUITO_NUMBER  MECHANISM_STATUS  \n",
       "0             27.0                 1  \n",
       "1             27.0                 0  \n",
       "2             24.0                 1  \n",
       "3             24.0                 0  \n",
       "4            100.0                 0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset2_path = r'C:\\Users\\rithv\\OneDrive\\Desktop\\cnn_rnn_models\\mosquito_resdev\\mosquito_modeling_data.csv' # Replace with your dataset path\n",
    "df = pd.read_csv(dataset2_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categorical variables\n",
    "df_encoded = pd.get_dummies(df, columns=['COUNTRY_NAME', 'VECTOR SPECIES'])\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df_encoded.drop('MECHANISM_STATUS', axis=1)  # Features\n",
    "y = df_encoded['MECHANISM_STATUS']               # Target variable\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (2744, 98)\n",
      "Test features shape: (686, 98)\n",
      "Training labels shape: (2744,)\n",
      "Test labels shape: (686,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the splits\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Test features shape:\", X_test.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Initialize the model\n",
    "# model = LogisticRegression()\n",
    "\n",
    "# # Train the model on the training data\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the training data\n",
    "# train_predictions = model.predict(X_train)\n",
    "# train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "# # Predict on the test data\n",
    "# test_predictions = model.predict(X_test)\n",
    "# test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# # Print out the training and test accuracy\n",
    "# print(f\"Training Accuracy: {train_accuracy}\")\n",
    "# print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# # Define the neural network\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self, input_size):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, 64)  # Input layer to hidden layer\n",
    "#         self.fc2 = nn.Linear(64, 32)          # Hidden layer to hidden layer\n",
    "#         self.fc3 = nn.Linear(32, 2)           # Hidden layer to output layer\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)  # No activation, as we'll use CrossEntropyLoss\n",
    "#         return x\n",
    "\n",
    "# # Prepare the data\n",
    "# # Convert the pandas DataFrame to torch tensors\n",
    "# X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "# X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "# y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# # Initialize the network and optimizer\n",
    "# input_size = X_train.shape[1]\n",
    "# net = Net(input_size)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Train the network\n",
    "# num_epochs = 100\n",
    "# for epoch in range(num_epochs):\n",
    "#     net.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     output = net(X_train_tensor)\n",
    "#     loss = criterion(output, y_train_tensor)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     # Print loss every 10 epochs\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# # Evaluate the network\n",
    "# net.eval()\n",
    "# with torch.no_grad():\n",
    "#     train_preds = torch.argmax(net(X_train_tensor), dim=1)\n",
    "#     train_accuracy = accuracy_score(y_train_tensor, train_preds)\n",
    "#     test_preds = torch.argmax(net(X_test_tensor), dim=1)\n",
    "#     test_accuracy = accuracy_score(y_test_tensor, test_preds)\n",
    "\n",
    "# print(f'Training Accuracy: {train_accuracy}')\n",
    "# print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                6336      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8449 (33.00 KB)\n",
      "Trainable params: 8449 (33.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X_train, X_test, y_train, and y_test are already defined as per your earlier code\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))  # Input layer\n",
    "model.add(Dense(32, activation='relu'))  # Hidden layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',  # Using binary_crossentropy for binary classification\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['COUNTRY_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 35/220 [===>..........................] - ETA: 0s - loss: 0.3245 - accuracy: 0.8343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rithv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1798: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8150 - val_loss: 0.5296 - val_accuracy: 0.7468\n",
      "Epoch 2/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8251 - val_loss: 0.5133 - val_accuracy: 0.7596\n",
      "Epoch 3/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8191 - val_loss: 0.5155 - val_accuracy: 0.7668\n",
      "Epoch 4/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8178 - val_loss: 0.5173 - val_accuracy: 0.7450\n",
      "Epoch 5/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8232 - val_loss: 0.5151 - val_accuracy: 0.7523\n",
      "Epoch 6/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8223 - val_loss: 0.5183 - val_accuracy: 0.7614\n",
      "Epoch 7/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8237 - val_loss: 0.5220 - val_accuracy: 0.7632\n",
      "Epoch 8/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8223 - val_loss: 0.5262 - val_accuracy: 0.7596\n",
      "Epoch 9/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8223 - val_loss: 0.5298 - val_accuracy: 0.7432\n",
      "Epoch 10/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8219 - val_loss: 0.5171 - val_accuracy: 0.7559\n",
      "Epoch 11/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8232 - val_loss: 0.5171 - val_accuracy: 0.7413\n",
      "Epoch 12/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8205 - val_loss: 0.5160 - val_accuracy: 0.7486\n",
      "Epoch 13/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8228 - val_loss: 0.5265 - val_accuracy: 0.7577\n",
      "Epoch 14/1000\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8196 - val_loss: 0.5190 - val_accuracy: 0.7559\n",
      "Epoch 15/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8210 - val_loss: 0.5276 - val_accuracy: 0.7395\n",
      "Epoch 16/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8223 - val_loss: 0.5199 - val_accuracy: 0.7632\n",
      "Epoch 17/1000\n",
      "220/220 [==============================] - 1s 2ms/step - loss: 0.3403 - accuracy: 0.8264 - val_loss: 0.5283 - val_accuracy: 0.7541\n",
      "Epoch 18/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8200 - val_loss: 0.5368 - val_accuracy: 0.7486\n",
      "Epoch 19/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8141 - val_loss: 0.5253 - val_accuracy: 0.7486\n",
      "Epoch 20/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8205 - val_loss: 0.5419 - val_accuracy: 0.7541\n",
      "Epoch 21/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8237 - val_loss: 0.5207 - val_accuracy: 0.7577\n",
      "Epoch 22/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8141 - val_loss: 0.5305 - val_accuracy: 0.7468\n",
      "Epoch 23/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8182 - val_loss: 0.5207 - val_accuracy: 0.7559\n",
      "Epoch 24/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8200 - val_loss: 0.5238 - val_accuracy: 0.7650\n",
      "Epoch 25/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3413 - accuracy: 0.8237 - val_loss: 0.5218 - val_accuracy: 0.7596\n",
      "Epoch 26/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8273 - val_loss: 0.5281 - val_accuracy: 0.7614\n",
      "Epoch 27/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8200 - val_loss: 0.5251 - val_accuracy: 0.7577\n",
      "Epoch 28/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8214 - val_loss: 0.5293 - val_accuracy: 0.7614\n",
      "Epoch 29/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8223 - val_loss: 0.5217 - val_accuracy: 0.7559\n",
      "Epoch 30/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8232 - val_loss: 0.5360 - val_accuracy: 0.7559\n",
      "Epoch 31/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8228 - val_loss: 0.5269 - val_accuracy: 0.7596\n",
      "Epoch 32/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8232 - val_loss: 0.5367 - val_accuracy: 0.7723\n",
      "Epoch 33/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8196 - val_loss: 0.5284 - val_accuracy: 0.7577\n",
      "Epoch 34/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8223 - val_loss: 0.5319 - val_accuracy: 0.7541\n",
      "Epoch 35/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8191 - val_loss: 0.5341 - val_accuracy: 0.7577\n",
      "Epoch 36/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8228 - val_loss: 0.5454 - val_accuracy: 0.7413\n",
      "Epoch 37/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8159 - val_loss: 0.5451 - val_accuracy: 0.7632\n",
      "Epoch 38/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8219 - val_loss: 0.5294 - val_accuracy: 0.7705\n",
      "Epoch 39/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8232 - val_loss: 0.5432 - val_accuracy: 0.7450\n",
      "Epoch 40/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8232 - val_loss: 0.5414 - val_accuracy: 0.7541\n",
      "Epoch 41/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8214 - val_loss: 0.5415 - val_accuracy: 0.7559\n",
      "Epoch 42/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8228 - val_loss: 0.5458 - val_accuracy: 0.7468\n",
      "Epoch 43/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8237 - val_loss: 0.5299 - val_accuracy: 0.7505\n",
      "Epoch 44/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8232 - val_loss: 0.5522 - val_accuracy: 0.7559\n",
      "Epoch 45/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8191 - val_loss: 0.5467 - val_accuracy: 0.7486\n",
      "Epoch 46/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8273 - val_loss: 0.5407 - val_accuracy: 0.7559\n",
      "Epoch 47/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8228 - val_loss: 0.5376 - val_accuracy: 0.7650\n",
      "Epoch 48/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8210 - val_loss: 0.5513 - val_accuracy: 0.7505\n",
      "Epoch 49/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8205 - val_loss: 0.5543 - val_accuracy: 0.7523\n",
      "Epoch 50/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8191 - val_loss: 0.5491 - val_accuracy: 0.7577\n",
      "Epoch 51/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8273 - val_loss: 0.5573 - val_accuracy: 0.7596\n",
      "Epoch 52/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8210 - val_loss: 0.5538 - val_accuracy: 0.7614\n",
      "Epoch 53/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8205 - val_loss: 0.5400 - val_accuracy: 0.7596\n",
      "Epoch 54/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8273 - val_loss: 0.5375 - val_accuracy: 0.7559\n",
      "Epoch 55/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8241 - val_loss: 0.5437 - val_accuracy: 0.7632\n",
      "Epoch 56/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8287 - val_loss: 0.5530 - val_accuracy: 0.7541\n",
      "Epoch 57/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8264 - val_loss: 0.5448 - val_accuracy: 0.7723\n",
      "Epoch 58/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8282 - val_loss: 0.5649 - val_accuracy: 0.7505\n",
      "Epoch 59/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8269 - val_loss: 0.5562 - val_accuracy: 0.7468\n",
      "Epoch 60/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8228 - val_loss: 0.5529 - val_accuracy: 0.7596\n",
      "Epoch 61/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8255 - val_loss: 0.5547 - val_accuracy: 0.7596\n",
      "Epoch 62/1000\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8269 - val_loss: 0.5523 - val_accuracy: 0.7650\n",
      "Epoch 63/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8228 - val_loss: 0.5537 - val_accuracy: 0.7577\n",
      "Epoch 64/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8196 - val_loss: 0.5453 - val_accuracy: 0.7577\n",
      "Epoch 65/1000\n",
      "220/220 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8251 - val_loss: 0.5557 - val_accuracy: 0.7650\n",
      "Epoch 66/1000\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8241 - val_loss: 0.5614 - val_accuracy: 0.7541\n",
      "Epoch 67/1000\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.3251 - accuracy: 0.8333 - val_loss: 0.5547 - val_accuracy: 0.7486\n",
      "Epoch 68/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8260 - val_loss: 0.5613 - val_accuracy: 0.7596\n",
      "Epoch 69/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8223 - val_loss: 0.5777 - val_accuracy: 0.7505\n",
      "Epoch 70/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8273 - val_loss: 0.5673 - val_accuracy: 0.7650\n",
      "Epoch 71/1000\n",
      "220/220 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8287 - val_loss: 0.5754 - val_accuracy: 0.7596\n",
      "Epoch 72/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8269 - val_loss: 0.5665 - val_accuracy: 0.7577\n",
      "Epoch 73/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8223 - val_loss: 0.5739 - val_accuracy: 0.7468\n",
      "Epoch 74/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8278 - val_loss: 0.5729 - val_accuracy: 0.7760\n",
      "Epoch 75/1000\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.3256 - accuracy: 0.8269 - val_loss: 0.5750 - val_accuracy: 0.7596\n",
      "Epoch 76/1000\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.8241 - val_loss: 0.5667 - val_accuracy: 0.7632\n",
      "Epoch 77/1000\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.8246 - val_loss: 0.5808 - val_accuracy: 0.7468\n",
      "Epoch 78/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8210 - val_loss: 0.5794 - val_accuracy: 0.7541\n",
      "Epoch 79/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8241 - val_loss: 0.5736 - val_accuracy: 0.7614\n",
      "Epoch 80/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8210 - val_loss: 0.5791 - val_accuracy: 0.7650\n",
      "Epoch 81/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8319 - val_loss: 0.5855 - val_accuracy: 0.7377\n",
      "Epoch 82/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8255 - val_loss: 0.5842 - val_accuracy: 0.7541\n",
      "Epoch 83/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3236 - accuracy: 0.8269 - val_loss: 0.5905 - val_accuracy: 0.7596\n",
      "Epoch 84/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8301 - val_loss: 0.5789 - val_accuracy: 0.7596\n",
      "Epoch 85/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.8310 - val_loss: 0.5815 - val_accuracy: 0.7486\n",
      "Epoch 86/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8241 - val_loss: 0.5904 - val_accuracy: 0.7541\n",
      "Epoch 87/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8301 - val_loss: 0.5846 - val_accuracy: 0.7505\n",
      "Epoch 88/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8246 - val_loss: 0.5912 - val_accuracy: 0.7505\n",
      "Epoch 89/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8255 - val_loss: 0.5847 - val_accuracy: 0.7468\n",
      "Epoch 90/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.8205 - val_loss: 0.5851 - val_accuracy: 0.7705\n",
      "Epoch 91/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8251 - val_loss: 0.6021 - val_accuracy: 0.7559\n",
      "Epoch 92/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8278 - val_loss: 0.5968 - val_accuracy: 0.7559\n",
      "Epoch 93/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8292 - val_loss: 0.5904 - val_accuracy: 0.7468\n",
      "Epoch 94/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3221 - accuracy: 0.8264 - val_loss: 0.5994 - val_accuracy: 0.7413\n",
      "Epoch 95/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8273 - val_loss: 0.5850 - val_accuracy: 0.7486\n",
      "Epoch 96/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8351 - val_loss: 0.6094 - val_accuracy: 0.7614\n",
      "Epoch 97/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3203 - accuracy: 0.8255 - val_loss: 0.5927 - val_accuracy: 0.7523\n",
      "Epoch 98/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8305 - val_loss: 0.5882 - val_accuracy: 0.7596\n",
      "Epoch 99/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8292 - val_loss: 0.6029 - val_accuracy: 0.7505\n",
      "Epoch 100/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8264 - val_loss: 0.5930 - val_accuracy: 0.7668\n",
      "Epoch 101/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8282 - val_loss: 0.5860 - val_accuracy: 0.7596\n",
      "Epoch 102/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8314 - val_loss: 0.6060 - val_accuracy: 0.7505\n",
      "Epoch 103/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8241 - val_loss: 0.6036 - val_accuracy: 0.7432\n",
      "Epoch 104/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8255 - val_loss: 0.6065 - val_accuracy: 0.7632\n",
      "Epoch 105/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8351 - val_loss: 0.6078 - val_accuracy: 0.7523\n",
      "Epoch 106/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8278 - val_loss: 0.6052 - val_accuracy: 0.7286\n",
      "Epoch 107/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8237 - val_loss: 0.6044 - val_accuracy: 0.7505\n",
      "Epoch 108/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3215 - accuracy: 0.8232 - val_loss: 0.6050 - val_accuracy: 0.7413\n",
      "Epoch 109/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8328 - val_loss: 0.5982 - val_accuracy: 0.7650\n",
      "Epoch 110/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8264 - val_loss: 0.6149 - val_accuracy: 0.7596\n",
      "Epoch 111/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8260 - val_loss: 0.5929 - val_accuracy: 0.7650\n",
      "Epoch 112/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8319 - val_loss: 0.6196 - val_accuracy: 0.7596\n",
      "Epoch 113/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8319 - val_loss: 0.6033 - val_accuracy: 0.7668\n",
      "Epoch 114/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8292 - val_loss: 0.6209 - val_accuracy: 0.7668\n",
      "Epoch 115/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8314 - val_loss: 0.6038 - val_accuracy: 0.7577\n",
      "Epoch 116/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3157 - accuracy: 0.8337 - val_loss: 0.5975 - val_accuracy: 0.7832\n",
      "Epoch 117/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8360 - val_loss: 0.6126 - val_accuracy: 0.7468\n",
      "Epoch 118/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8301 - val_loss: 0.6081 - val_accuracy: 0.7614\n",
      "Epoch 119/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8310 - val_loss: 0.6155 - val_accuracy: 0.7596\n",
      "Epoch 120/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8319 - val_loss: 0.6198 - val_accuracy: 0.7614\n",
      "Epoch 121/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8305 - val_loss: 0.6186 - val_accuracy: 0.7450\n",
      "Epoch 122/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8287 - val_loss: 0.6028 - val_accuracy: 0.7596\n",
      "Epoch 123/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8278 - val_loss: 0.6131 - val_accuracy: 0.7541\n",
      "Epoch 124/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8269 - val_loss: 0.6102 - val_accuracy: 0.7559\n",
      "Epoch 125/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8287 - val_loss: 0.6110 - val_accuracy: 0.7687\n",
      "Epoch 126/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8296 - val_loss: 0.6156 - val_accuracy: 0.7650\n",
      "Epoch 127/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8273 - val_loss: 0.6360 - val_accuracy: 0.7614\n",
      "Epoch 128/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3164 - accuracy: 0.8287 - val_loss: 0.6342 - val_accuracy: 0.7596\n",
      "Epoch 129/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8328 - val_loss: 0.6199 - val_accuracy: 0.7687\n",
      "Epoch 130/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8342 - val_loss: 0.6321 - val_accuracy: 0.7523\n",
      "Epoch 131/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8260 - val_loss: 0.6302 - val_accuracy: 0.7505\n",
      "Epoch 132/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3124 - accuracy: 0.8342 - val_loss: 0.6237 - val_accuracy: 0.7505\n",
      "Epoch 133/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8310 - val_loss: 0.6302 - val_accuracy: 0.7505\n",
      "Epoch 134/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8296 - val_loss: 0.6476 - val_accuracy: 0.7614\n",
      "Epoch 135/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8287 - val_loss: 0.6204 - val_accuracy: 0.7559\n",
      "Epoch 136/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8364 - val_loss: 0.6165 - val_accuracy: 0.7668\n",
      "Epoch 137/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8328 - val_loss: 0.6249 - val_accuracy: 0.7432\n",
      "Epoch 138/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8296 - val_loss: 0.6335 - val_accuracy: 0.7559\n",
      "Epoch 139/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8369 - val_loss: 0.6172 - val_accuracy: 0.7723\n",
      "Epoch 140/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8369 - val_loss: 0.6176 - val_accuracy: 0.7650\n",
      "Epoch 141/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8310 - val_loss: 0.6289 - val_accuracy: 0.7541\n",
      "Epoch 142/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8269 - val_loss: 0.6390 - val_accuracy: 0.7577\n",
      "Epoch 143/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8342 - val_loss: 0.6277 - val_accuracy: 0.7650\n",
      "Epoch 144/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8296 - val_loss: 0.6280 - val_accuracy: 0.7486\n",
      "Epoch 145/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8342 - val_loss: 0.6288 - val_accuracy: 0.7741\n",
      "Epoch 146/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8346 - val_loss: 0.6331 - val_accuracy: 0.7559\n",
      "Epoch 147/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8287 - val_loss: 0.6325 - val_accuracy: 0.7541\n",
      "Epoch 148/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8328 - val_loss: 0.6273 - val_accuracy: 0.7632\n",
      "Epoch 149/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3129 - accuracy: 0.8342 - val_loss: 0.6470 - val_accuracy: 0.7505\n",
      "Epoch 150/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8328 - val_loss: 0.6514 - val_accuracy: 0.7541\n",
      "Epoch 151/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8383 - val_loss: 0.6405 - val_accuracy: 0.7486\n",
      "Epoch 152/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3118 - accuracy: 0.8410 - val_loss: 0.6254 - val_accuracy: 0.7523\n",
      "Epoch 153/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8451 - val_loss: 0.6407 - val_accuracy: 0.7523\n",
      "Epoch 154/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8342 - val_loss: 0.6554 - val_accuracy: 0.7632\n",
      "Epoch 155/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8264 - val_loss: 0.6442 - val_accuracy: 0.7395\n",
      "Epoch 156/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3120 - accuracy: 0.8323 - val_loss: 0.6450 - val_accuracy: 0.7486\n",
      "Epoch 157/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8314 - val_loss: 0.6417 - val_accuracy: 0.7486\n",
      "Epoch 158/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8374 - val_loss: 0.6346 - val_accuracy: 0.7668\n",
      "Epoch 159/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8360 - val_loss: 0.6320 - val_accuracy: 0.7577\n",
      "Epoch 160/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3113 - accuracy: 0.8323 - val_loss: 0.6682 - val_accuracy: 0.7505\n",
      "Epoch 161/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8310 - val_loss: 0.6657 - val_accuracy: 0.7450\n",
      "Epoch 162/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3114 - accuracy: 0.8278 - val_loss: 0.6411 - val_accuracy: 0.7523\n",
      "Epoch 163/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8333 - val_loss: 0.6411 - val_accuracy: 0.7596\n",
      "Epoch 164/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.8310 - val_loss: 0.6611 - val_accuracy: 0.7596\n",
      "Epoch 165/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8369 - val_loss: 0.6549 - val_accuracy: 0.7577\n",
      "Epoch 166/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.8333 - val_loss: 0.6688 - val_accuracy: 0.7468\n",
      "Epoch 167/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8342 - val_loss: 0.6496 - val_accuracy: 0.7741\n",
      "Epoch 168/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8383 - val_loss: 0.6586 - val_accuracy: 0.7523\n",
      "Epoch 169/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8342 - val_loss: 0.6452 - val_accuracy: 0.7559\n",
      "Epoch 170/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8355 - val_loss: 0.6377 - val_accuracy: 0.7614\n",
      "Epoch 171/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8374 - val_loss: 0.6644 - val_accuracy: 0.7505\n",
      "Epoch 172/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.8264 - val_loss: 0.6797 - val_accuracy: 0.7559\n",
      "Epoch 173/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8351 - val_loss: 0.6623 - val_accuracy: 0.7541\n",
      "Epoch 174/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8383 - val_loss: 0.6522 - val_accuracy: 0.7541\n",
      "Epoch 175/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8383 - val_loss: 0.6567 - val_accuracy: 0.7505\n",
      "Epoch 176/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8346 - val_loss: 0.6616 - val_accuracy: 0.7596\n",
      "Epoch 177/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8333 - val_loss: 0.6596 - val_accuracy: 0.7596\n",
      "Epoch 178/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8378 - val_loss: 0.6611 - val_accuracy: 0.7614\n",
      "Epoch 179/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8342 - val_loss: 0.6576 - val_accuracy: 0.7596\n",
      "Epoch 180/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8342 - val_loss: 0.6710 - val_accuracy: 0.7632\n",
      "Epoch 181/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8346 - val_loss: 0.6539 - val_accuracy: 0.7668\n",
      "Epoch 182/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3057 - accuracy: 0.8387 - val_loss: 0.6684 - val_accuracy: 0.7541\n",
      "Epoch 183/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8355 - val_loss: 0.6719 - val_accuracy: 0.7505\n",
      "Epoch 184/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3039 - accuracy: 0.8333 - val_loss: 0.6583 - val_accuracy: 0.7541\n",
      "Epoch 185/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8410 - val_loss: 0.6645 - val_accuracy: 0.7541\n",
      "Epoch 186/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8387 - val_loss: 0.6709 - val_accuracy: 0.7577\n",
      "Epoch 187/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8369 - val_loss: 0.6621 - val_accuracy: 0.7723\n",
      "Epoch 188/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8314 - val_loss: 0.6526 - val_accuracy: 0.7632\n",
      "Epoch 189/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8346 - val_loss: 0.6513 - val_accuracy: 0.7577\n",
      "Epoch 190/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3047 - accuracy: 0.8369 - val_loss: 0.6628 - val_accuracy: 0.7705\n",
      "Epoch 191/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8396 - val_loss: 0.6648 - val_accuracy: 0.7687\n",
      "Epoch 192/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8346 - val_loss: 0.6780 - val_accuracy: 0.7559\n",
      "Epoch 193/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8374 - val_loss: 0.6583 - val_accuracy: 0.7596\n",
      "Epoch 194/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3037 - accuracy: 0.8374 - val_loss: 0.6723 - val_accuracy: 0.7596\n",
      "Epoch 195/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8342 - val_loss: 0.6653 - val_accuracy: 0.7559\n",
      "Epoch 196/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3036 - accuracy: 0.8360 - val_loss: 0.6686 - val_accuracy: 0.7559\n",
      "Epoch 197/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8387 - val_loss: 0.6577 - val_accuracy: 0.7668\n",
      "Epoch 198/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8374 - val_loss: 0.6695 - val_accuracy: 0.7596\n",
      "Epoch 199/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8378 - val_loss: 0.6815 - val_accuracy: 0.7523\n",
      "Epoch 200/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2997 - accuracy: 0.8469 - val_loss: 0.6805 - val_accuracy: 0.7614\n",
      "Epoch 201/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.8351 - val_loss: 0.6839 - val_accuracy: 0.7523\n",
      "Epoch 202/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8342 - val_loss: 0.6754 - val_accuracy: 0.7577\n",
      "Epoch 203/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8355 - val_loss: 0.6839 - val_accuracy: 0.7523\n",
      "Epoch 204/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8374 - val_loss: 0.6805 - val_accuracy: 0.7614\n",
      "Epoch 205/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8369 - val_loss: 0.6696 - val_accuracy: 0.7632\n",
      "Epoch 206/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3000 - accuracy: 0.8369 - val_loss: 0.6922 - val_accuracy: 0.7541\n",
      "Epoch 207/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8374 - val_loss: 0.6879 - val_accuracy: 0.7650\n",
      "Epoch 208/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8369 - val_loss: 0.6771 - val_accuracy: 0.7559\n",
      "Epoch 209/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3010 - accuracy: 0.8387 - val_loss: 0.7141 - val_accuracy: 0.7395\n",
      "Epoch 210/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8378 - val_loss: 0.6903 - val_accuracy: 0.7687\n",
      "Epoch 211/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8419 - val_loss: 0.6898 - val_accuracy: 0.7523\n",
      "Epoch 212/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8383 - val_loss: 0.6757 - val_accuracy: 0.7614\n",
      "Epoch 213/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8374 - val_loss: 0.6913 - val_accuracy: 0.7596\n",
      "Epoch 214/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3021 - accuracy: 0.8392 - val_loss: 0.6938 - val_accuracy: 0.7632\n",
      "Epoch 215/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8419 - val_loss: 0.6812 - val_accuracy: 0.7668\n",
      "Epoch 216/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8392 - val_loss: 0.6861 - val_accuracy: 0.7596\n",
      "Epoch 217/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8415 - val_loss: 0.6972 - val_accuracy: 0.7559\n",
      "Epoch 218/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.8351 - val_loss: 0.6971 - val_accuracy: 0.7741\n",
      "Epoch 219/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8355 - val_loss: 0.7064 - val_accuracy: 0.7559\n",
      "Epoch 220/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8383 - val_loss: 0.6905 - val_accuracy: 0.7596\n",
      "Epoch 221/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8342 - val_loss: 0.6912 - val_accuracy: 0.7632\n",
      "Epoch 222/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8383 - val_loss: 0.6893 - val_accuracy: 0.7577\n",
      "Epoch 223/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8424 - val_loss: 0.6871 - val_accuracy: 0.7668\n",
      "Epoch 224/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.8387 - val_loss: 0.7088 - val_accuracy: 0.7523\n",
      "Epoch 225/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8396 - val_loss: 0.6971 - val_accuracy: 0.7614\n",
      "Epoch 226/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8401 - val_loss: 0.7110 - val_accuracy: 0.7559\n",
      "Epoch 227/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8374 - val_loss: 0.7012 - val_accuracy: 0.7577\n",
      "Epoch 228/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2985 - accuracy: 0.8401 - val_loss: 0.6940 - val_accuracy: 0.7632\n",
      "Epoch 229/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8392 - val_loss: 0.7001 - val_accuracy: 0.7559\n",
      "Epoch 230/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2979 - accuracy: 0.8424 - val_loss: 0.7119 - val_accuracy: 0.7596\n",
      "Epoch 231/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2973 - accuracy: 0.8396 - val_loss: 0.7088 - val_accuracy: 0.7486\n",
      "Epoch 232/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8415 - val_loss: 0.7026 - val_accuracy: 0.7668\n",
      "Epoch 233/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8364 - val_loss: 0.7131 - val_accuracy: 0.7559\n",
      "Epoch 234/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8419 - val_loss: 0.6912 - val_accuracy: 0.7650\n",
      "Epoch 235/1000\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.2950 - accuracy: 0.8437 - val_loss: 0.7099 - val_accuracy: 0.7559\n",
      "Epoch 236/1000\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.2994 - accuracy: 0.8428 - val_loss: 0.7143 - val_accuracy: 0.7541\n",
      "Epoch 237/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8392 - val_loss: 0.7052 - val_accuracy: 0.7614\n",
      "Epoch 238/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8383 - val_loss: 0.7023 - val_accuracy: 0.7541\n",
      "Epoch 239/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8428 - val_loss: 0.7001 - val_accuracy: 0.7705\n",
      "Epoch 240/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8410 - val_loss: 0.7178 - val_accuracy: 0.7596\n",
      "Epoch 241/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8323 - val_loss: 0.7110 - val_accuracy: 0.7523\n",
      "Epoch 242/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8405 - val_loss: 0.7171 - val_accuracy: 0.7541\n",
      "Epoch 243/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8424 - val_loss: 0.7267 - val_accuracy: 0.7687\n",
      "Epoch 244/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.8401 - val_loss: 0.7300 - val_accuracy: 0.7614\n",
      "Epoch 245/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8405 - val_loss: 0.7117 - val_accuracy: 0.7632\n",
      "Epoch 246/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8415 - val_loss: 0.7410 - val_accuracy: 0.7577\n",
      "Epoch 247/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8360 - val_loss: 0.7115 - val_accuracy: 0.7723\n",
      "Epoch 248/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.8451 - val_loss: 0.7140 - val_accuracy: 0.7541\n",
      "Epoch 249/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2962 - accuracy: 0.8378 - val_loss: 0.7239 - val_accuracy: 0.7650\n",
      "Epoch 250/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8428 - val_loss: 0.7083 - val_accuracy: 0.7723\n",
      "Epoch 251/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2965 - accuracy: 0.8378 - val_loss: 0.7213 - val_accuracy: 0.7632\n",
      "Epoch 252/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.8405 - val_loss: 0.7106 - val_accuracy: 0.7741\n",
      "Epoch 253/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8369 - val_loss: 0.7287 - val_accuracy: 0.7650\n",
      "Epoch 254/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8401 - val_loss: 0.7288 - val_accuracy: 0.7705\n",
      "Epoch 255/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8415 - val_loss: 0.7234 - val_accuracy: 0.7632\n",
      "Epoch 256/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.8424 - val_loss: 0.7326 - val_accuracy: 0.7577\n",
      "Epoch 257/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8401 - val_loss: 0.7265 - val_accuracy: 0.7668\n",
      "Epoch 258/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8433 - val_loss: 0.7512 - val_accuracy: 0.7468\n",
      "Epoch 259/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.8401 - val_loss: 0.7086 - val_accuracy: 0.7668\n",
      "Epoch 260/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8392 - val_loss: 0.7187 - val_accuracy: 0.7596\n",
      "Epoch 261/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2935 - accuracy: 0.8378 - val_loss: 0.7230 - val_accuracy: 0.7486\n",
      "Epoch 262/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8374 - val_loss: 0.7179 - val_accuracy: 0.7723\n",
      "Epoch 263/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8401 - val_loss: 0.7079 - val_accuracy: 0.7614\n",
      "Epoch 264/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8392 - val_loss: 0.7265 - val_accuracy: 0.7577\n",
      "Epoch 265/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2941 - accuracy: 0.8355 - val_loss: 0.7253 - val_accuracy: 0.7577\n",
      "Epoch 266/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2969 - accuracy: 0.8396 - val_loss: 0.7199 - val_accuracy: 0.7596\n",
      "Epoch 267/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2978 - accuracy: 0.8364 - val_loss: 0.7206 - val_accuracy: 0.7650\n",
      "Epoch 268/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8410 - val_loss: 0.7268 - val_accuracy: 0.7650\n",
      "Epoch 269/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8442 - val_loss: 0.7327 - val_accuracy: 0.7687\n",
      "Epoch 270/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8378 - val_loss: 0.7379 - val_accuracy: 0.7505\n",
      "Epoch 271/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8392 - val_loss: 0.7389 - val_accuracy: 0.7577\n",
      "Epoch 272/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8378 - val_loss: 0.7246 - val_accuracy: 0.7614\n",
      "Epoch 273/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8360 - val_loss: 0.7306 - val_accuracy: 0.7596\n",
      "Epoch 274/1000\n",
      "220/220 [==============================] - 1s 2ms/step - loss: 0.2928 - accuracy: 0.8442 - val_loss: 0.7529 - val_accuracy: 0.7577\n",
      "Epoch 275/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8387 - val_loss: 0.7443 - val_accuracy: 0.7614\n",
      "Epoch 276/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2932 - accuracy: 0.8396 - val_loss: 0.7363 - val_accuracy: 0.7614\n",
      "Epoch 277/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8392 - val_loss: 0.7427 - val_accuracy: 0.7705\n",
      "Epoch 278/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8387 - val_loss: 0.7447 - val_accuracy: 0.7668\n",
      "Epoch 279/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8405 - val_loss: 0.7518 - val_accuracy: 0.7523\n",
      "Epoch 280/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.8415 - val_loss: 0.7422 - val_accuracy: 0.7650\n",
      "Epoch 281/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8374 - val_loss: 0.7541 - val_accuracy: 0.7505\n",
      "Epoch 282/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.8424 - val_loss: 0.7322 - val_accuracy: 0.7505\n",
      "Epoch 283/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8351 - val_loss: 0.7438 - val_accuracy: 0.7559\n",
      "Epoch 284/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.8383 - val_loss: 0.7267 - val_accuracy: 0.7650\n",
      "Epoch 285/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8437 - val_loss: 0.7519 - val_accuracy: 0.7632\n",
      "Epoch 286/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.8433 - val_loss: 0.7276 - val_accuracy: 0.7632\n",
      "Epoch 287/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8392 - val_loss: 0.7377 - val_accuracy: 0.7468\n",
      "Epoch 288/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2907 - accuracy: 0.8437 - val_loss: 0.7598 - val_accuracy: 0.7505\n",
      "Epoch 289/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8424 - val_loss: 0.7208 - val_accuracy: 0.7723\n",
      "Epoch 290/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2901 - accuracy: 0.8465 - val_loss: 0.7432 - val_accuracy: 0.7741\n",
      "Epoch 291/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8428 - val_loss: 0.7328 - val_accuracy: 0.7614\n",
      "Epoch 292/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.8415 - val_loss: 0.7554 - val_accuracy: 0.7632\n",
      "Epoch 293/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8428 - val_loss: 0.7441 - val_accuracy: 0.7632\n",
      "Epoch 294/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2924 - accuracy: 0.8378 - val_loss: 0.7474 - val_accuracy: 0.7541\n",
      "Epoch 295/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.8374 - val_loss: 0.7484 - val_accuracy: 0.7486\n",
      "Epoch 296/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8428 - val_loss: 0.7430 - val_accuracy: 0.7541\n",
      "Epoch 297/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8451 - val_loss: 0.7461 - val_accuracy: 0.7596\n",
      "Epoch 298/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2935 - accuracy: 0.8337 - val_loss: 0.7577 - val_accuracy: 0.7596\n",
      "Epoch 299/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8419 - val_loss: 0.7555 - val_accuracy: 0.7559\n",
      "Epoch 300/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2921 - accuracy: 0.8437 - val_loss: 0.7488 - val_accuracy: 0.7523\n",
      "Epoch 301/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.8396 - val_loss: 0.7392 - val_accuracy: 0.7760\n",
      "Epoch 302/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.8401 - val_loss: 0.7621 - val_accuracy: 0.7668\n",
      "Epoch 303/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8428 - val_loss: 0.7549 - val_accuracy: 0.7559\n",
      "Epoch 304/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8469 - val_loss: 0.7369 - val_accuracy: 0.7541\n",
      "Epoch 305/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.8419 - val_loss: 0.7514 - val_accuracy: 0.7614\n",
      "Epoch 306/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2896 - accuracy: 0.8446 - val_loss: 0.7602 - val_accuracy: 0.7650\n",
      "Epoch 307/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.8314 - val_loss: 0.7554 - val_accuracy: 0.7668\n",
      "Epoch 308/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.8369 - val_loss: 0.7575 - val_accuracy: 0.7523\n",
      "Epoch 309/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8460 - val_loss: 0.7616 - val_accuracy: 0.7650\n",
      "Epoch 310/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8415 - val_loss: 0.7581 - val_accuracy: 0.7614\n",
      "Epoch 311/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.8428 - val_loss: 0.7521 - val_accuracy: 0.7577\n",
      "Epoch 312/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2900 - accuracy: 0.8424 - val_loss: 0.7631 - val_accuracy: 0.7577\n",
      "Epoch 313/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8442 - val_loss: 0.7621 - val_accuracy: 0.7723\n",
      "Epoch 314/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8355 - val_loss: 0.7588 - val_accuracy: 0.7632\n",
      "Epoch 315/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.8437 - val_loss: 0.7540 - val_accuracy: 0.7577\n",
      "Epoch 316/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2899 - accuracy: 0.8446 - val_loss: 0.7552 - val_accuracy: 0.7541\n",
      "Epoch 317/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8424 - val_loss: 0.7518 - val_accuracy: 0.7596\n",
      "Epoch 318/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8396 - val_loss: 0.7633 - val_accuracy: 0.7468\n",
      "Epoch 319/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.8405 - val_loss: 0.7537 - val_accuracy: 0.7577\n",
      "Epoch 320/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8401 - val_loss: 0.7790 - val_accuracy: 0.7632\n",
      "Epoch 321/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.8419 - val_loss: 0.7632 - val_accuracy: 0.7596\n",
      "Epoch 322/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8442 - val_loss: 0.7576 - val_accuracy: 0.7650\n",
      "Epoch 323/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2888 - accuracy: 0.8424 - val_loss: 0.7732 - val_accuracy: 0.7541\n",
      "Epoch 324/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.8460 - val_loss: 0.7686 - val_accuracy: 0.7505\n",
      "Epoch 325/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8424 - val_loss: 0.7636 - val_accuracy: 0.7577\n",
      "Epoch 326/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.8387 - val_loss: 0.7653 - val_accuracy: 0.7523\n",
      "Epoch 327/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2878 - accuracy: 0.8446 - val_loss: 0.7449 - val_accuracy: 0.7577\n",
      "Epoch 328/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8428 - val_loss: 0.7842 - val_accuracy: 0.7413\n",
      "Epoch 329/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8433 - val_loss: 0.7615 - val_accuracy: 0.7632\n",
      "Epoch 330/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8419 - val_loss: 0.7685 - val_accuracy: 0.7632\n",
      "Epoch 331/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8428 - val_loss: 0.7696 - val_accuracy: 0.7541\n",
      "Epoch 332/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.8428 - val_loss: 0.7727 - val_accuracy: 0.7577\n",
      "Epoch 333/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.8360 - val_loss: 0.7788 - val_accuracy: 0.7523\n",
      "Epoch 334/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8460 - val_loss: 0.7642 - val_accuracy: 0.7614\n",
      "Epoch 335/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2850 - accuracy: 0.8465 - val_loss: 0.7961 - val_accuracy: 0.7614\n",
      "Epoch 336/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8419 - val_loss: 0.7954 - val_accuracy: 0.7559\n",
      "Epoch 337/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.8428 - val_loss: 0.7961 - val_accuracy: 0.7650\n",
      "Epoch 338/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.8428 - val_loss: 0.7931 - val_accuracy: 0.7596\n",
      "Epoch 339/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8428 - val_loss: 0.7872 - val_accuracy: 0.7577\n",
      "Epoch 340/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.8465 - val_loss: 0.7926 - val_accuracy: 0.7614\n",
      "Epoch 341/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8428 - val_loss: 0.7922 - val_accuracy: 0.7559\n",
      "Epoch 342/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8510 - val_loss: 0.7842 - val_accuracy: 0.7559\n",
      "Epoch 343/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.8374 - val_loss: 0.7956 - val_accuracy: 0.7523\n",
      "Epoch 344/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8465 - val_loss: 0.7934 - val_accuracy: 0.7668\n",
      "Epoch 345/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2877 - accuracy: 0.8437 - val_loss: 0.7880 - val_accuracy: 0.7596\n",
      "Epoch 346/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8474 - val_loss: 0.7904 - val_accuracy: 0.7486\n",
      "Epoch 347/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8392 - val_loss: 0.8067 - val_accuracy: 0.7541\n",
      "Epoch 348/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8474 - val_loss: 0.7973 - val_accuracy: 0.7596\n",
      "Epoch 349/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.8446 - val_loss: 0.8093 - val_accuracy: 0.7632\n",
      "Epoch 350/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.8442 - val_loss: 0.8115 - val_accuracy: 0.7559\n",
      "Epoch 351/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2854 - accuracy: 0.8497 - val_loss: 0.8149 - val_accuracy: 0.7687\n",
      "Epoch 352/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8460 - val_loss: 0.8072 - val_accuracy: 0.7778\n",
      "Epoch 353/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2868 - accuracy: 0.8437 - val_loss: 0.8046 - val_accuracy: 0.7741\n",
      "Epoch 354/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8506 - val_loss: 0.8178 - val_accuracy: 0.7705\n",
      "Epoch 355/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2877 - accuracy: 0.8419 - val_loss: 0.7813 - val_accuracy: 0.7614\n",
      "Epoch 356/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8374 - val_loss: 0.7914 - val_accuracy: 0.7596\n",
      "Epoch 357/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8515 - val_loss: 0.8373 - val_accuracy: 0.7650\n",
      "Epoch 358/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8446 - val_loss: 0.8159 - val_accuracy: 0.7559\n",
      "Epoch 359/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.8392 - val_loss: 0.7868 - val_accuracy: 0.7541\n",
      "Epoch 360/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8487 - val_loss: 0.7994 - val_accuracy: 0.7668\n",
      "Epoch 361/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8428 - val_loss: 0.7915 - val_accuracy: 0.7450\n",
      "Epoch 362/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.8492 - val_loss: 0.8056 - val_accuracy: 0.7559\n",
      "Epoch 363/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8383 - val_loss: 0.8080 - val_accuracy: 0.7596\n",
      "Epoch 364/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8487 - val_loss: 0.7962 - val_accuracy: 0.7614\n",
      "Epoch 365/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.8442 - val_loss: 0.7861 - val_accuracy: 0.7614\n",
      "Epoch 366/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.8419 - val_loss: 0.8041 - val_accuracy: 0.7541\n",
      "Epoch 367/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.8424 - val_loss: 0.7995 - val_accuracy: 0.7723\n",
      "Epoch 368/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8460 - val_loss: 0.8018 - val_accuracy: 0.7760\n",
      "Epoch 369/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8437 - val_loss: 0.8363 - val_accuracy: 0.7523\n",
      "Epoch 370/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2870 - accuracy: 0.8433 - val_loss: 0.7901 - val_accuracy: 0.7577\n",
      "Epoch 371/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.8474 - val_loss: 0.8018 - val_accuracy: 0.7596\n",
      "Epoch 372/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.8506 - val_loss: 0.8139 - val_accuracy: 0.7760\n",
      "Epoch 373/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8451 - val_loss: 0.8167 - val_accuracy: 0.7668\n",
      "Epoch 374/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8460 - val_loss: 0.8339 - val_accuracy: 0.7632\n",
      "Epoch 375/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2872 - accuracy: 0.8456 - val_loss: 0.7880 - val_accuracy: 0.7687\n",
      "Epoch 376/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.8378 - val_loss: 0.7969 - val_accuracy: 0.7614\n",
      "Epoch 377/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8465 - val_loss: 0.8098 - val_accuracy: 0.7596\n",
      "Epoch 378/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8437 - val_loss: 0.8040 - val_accuracy: 0.7541\n",
      "Epoch 379/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.8483 - val_loss: 0.8134 - val_accuracy: 0.7632\n",
      "Epoch 380/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2852 - accuracy: 0.8465 - val_loss: 0.8096 - val_accuracy: 0.7614\n",
      "Epoch 381/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.8510 - val_loss: 0.8244 - val_accuracy: 0.7668\n",
      "Epoch 382/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.8474 - val_loss: 0.8034 - val_accuracy: 0.7650\n",
      "Epoch 383/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.8465 - val_loss: 0.8134 - val_accuracy: 0.7596\n",
      "Epoch 384/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8469 - val_loss: 0.8237 - val_accuracy: 0.7450\n",
      "Epoch 385/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8442 - val_loss: 0.8147 - val_accuracy: 0.7541\n",
      "Epoch 386/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.8474 - val_loss: 0.8133 - val_accuracy: 0.7668\n",
      "Epoch 387/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.8428 - val_loss: 0.8218 - val_accuracy: 0.7614\n",
      "Epoch 388/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8446 - val_loss: 0.8267 - val_accuracy: 0.7596\n",
      "Epoch 389/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2826 - accuracy: 0.8460 - val_loss: 0.8301 - val_accuracy: 0.7450\n",
      "Epoch 390/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.8483 - val_loss: 0.8080 - val_accuracy: 0.7723\n",
      "Epoch 391/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.8451 - val_loss: 0.8380 - val_accuracy: 0.7559\n",
      "Epoch 392/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8474 - val_loss: 0.8182 - val_accuracy: 0.7614\n",
      "Epoch 393/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.8428 - val_loss: 0.8419 - val_accuracy: 0.7596\n",
      "Epoch 394/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.8446 - val_loss: 0.8485 - val_accuracy: 0.7577\n",
      "Epoch 395/1000\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.2841 - accuracy: 0.8437 - val_loss: 0.8206 - val_accuracy: 0.7632\n",
      "Epoch 396/1000\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.2847 - accuracy: 0.8456 - val_loss: 0.8352 - val_accuracy: 0.7723\n",
      "Epoch 397/1000\n",
      "220/220 [==============================] - 1s 3ms/step - loss: 0.2838 - accuracy: 0.8383 - val_loss: 0.8576 - val_accuracy: 0.7541\n",
      "Epoch 398/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.8465 - val_loss: 0.8162 - val_accuracy: 0.7541\n",
      "Epoch 399/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.8487 - val_loss: 0.8465 - val_accuracy: 0.7505\n",
      "Epoch 400/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8442 - val_loss: 0.8404 - val_accuracy: 0.7650\n",
      "Epoch 401/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2840 - accuracy: 0.8442 - val_loss: 0.8485 - val_accuracy: 0.7559\n",
      "Epoch 402/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.8374 - val_loss: 0.8316 - val_accuracy: 0.7614\n",
      "Epoch 403/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8428 - val_loss: 0.8498 - val_accuracy: 0.7668\n",
      "Epoch 404/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8433 - val_loss: 0.8228 - val_accuracy: 0.7650\n",
      "Epoch 405/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.8469 - val_loss: 0.8655 - val_accuracy: 0.7577\n",
      "Epoch 406/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.8410 - val_loss: 0.8414 - val_accuracy: 0.7650\n",
      "Epoch 407/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2822 - accuracy: 0.8492 - val_loss: 0.8509 - val_accuracy: 0.7614\n",
      "Epoch 408/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2831 - accuracy: 0.8442 - val_loss: 0.8687 - val_accuracy: 0.7596\n",
      "Epoch 409/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.8437 - val_loss: 0.8511 - val_accuracy: 0.7614\n",
      "Epoch 410/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.8456 - val_loss: 0.8874 - val_accuracy: 0.7596\n",
      "Epoch 411/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8478 - val_loss: 0.8609 - val_accuracy: 0.7614\n",
      "Epoch 412/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2809 - accuracy: 0.8478 - val_loss: 0.8621 - val_accuracy: 0.7668\n",
      "Epoch 413/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8456 - val_loss: 0.8599 - val_accuracy: 0.7614\n",
      "Epoch 414/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.8465 - val_loss: 0.8482 - val_accuracy: 0.7541\n",
      "Epoch 415/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2819 - accuracy: 0.8483 - val_loss: 0.8556 - val_accuracy: 0.7523\n",
      "Epoch 416/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2788 - accuracy: 0.8478 - val_loss: 0.8688 - val_accuracy: 0.7541\n",
      "Epoch 417/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8478 - val_loss: 0.8601 - val_accuracy: 0.7577\n",
      "Epoch 418/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.8460 - val_loss: 0.8584 - val_accuracy: 0.7541\n",
      "Epoch 419/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.8469 - val_loss: 0.8693 - val_accuracy: 0.7632\n",
      "Epoch 420/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.8460 - val_loss: 0.8767 - val_accuracy: 0.7559\n",
      "Epoch 421/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8392 - val_loss: 0.8822 - val_accuracy: 0.7596\n",
      "Epoch 422/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.8424 - val_loss: 0.8818 - val_accuracy: 0.7523\n",
      "Epoch 423/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.8460 - val_loss: 0.8816 - val_accuracy: 0.7559\n",
      "Epoch 424/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.8492 - val_loss: 0.8879 - val_accuracy: 0.7705\n",
      "Epoch 425/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8428 - val_loss: 0.8704 - val_accuracy: 0.7614\n",
      "Epoch 426/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8428 - val_loss: 0.8739 - val_accuracy: 0.7577\n",
      "Epoch 427/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8424 - val_loss: 0.8606 - val_accuracy: 0.7577\n",
      "Epoch 428/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.8456 - val_loss: 0.8642 - val_accuracy: 0.7559\n",
      "Epoch 429/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.8519 - val_loss: 0.8506 - val_accuracy: 0.7614\n",
      "Epoch 430/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8456 - val_loss: 0.8560 - val_accuracy: 0.7668\n",
      "Epoch 431/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8446 - val_loss: 0.8679 - val_accuracy: 0.7614\n",
      "Epoch 432/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.8392 - val_loss: 0.8752 - val_accuracy: 0.7632\n",
      "Epoch 433/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2809 - accuracy: 0.8474 - val_loss: 0.8786 - val_accuracy: 0.7614\n",
      "Epoch 434/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.8460 - val_loss: 0.8752 - val_accuracy: 0.7632\n",
      "Epoch 435/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8442 - val_loss: 0.8690 - val_accuracy: 0.7650\n",
      "Epoch 436/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.8456 - val_loss: 0.8750 - val_accuracy: 0.7614\n",
      "Epoch 437/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2801 - accuracy: 0.8456 - val_loss: 0.8727 - val_accuracy: 0.7541\n",
      "Epoch 438/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2804 - accuracy: 0.8451 - val_loss: 0.8710 - val_accuracy: 0.7559\n",
      "Epoch 439/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.8460 - val_loss: 0.8740 - val_accuracy: 0.7541\n",
      "Epoch 440/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8446 - val_loss: 0.8853 - val_accuracy: 0.7523\n",
      "Epoch 441/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.8515 - val_loss: 0.8558 - val_accuracy: 0.7577\n",
      "Epoch 442/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2785 - accuracy: 0.8519 - val_loss: 0.8711 - val_accuracy: 0.7650\n",
      "Epoch 443/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8446 - val_loss: 0.8667 - val_accuracy: 0.7523\n",
      "Epoch 444/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.8456 - val_loss: 0.8760 - val_accuracy: 0.7559\n",
      "Epoch 445/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8378 - val_loss: 0.8897 - val_accuracy: 0.7650\n",
      "Epoch 446/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.8483 - val_loss: 0.8801 - val_accuracy: 0.7596\n",
      "Epoch 447/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2809 - accuracy: 0.8424 - val_loss: 0.8774 - val_accuracy: 0.7541\n",
      "Epoch 448/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8474 - val_loss: 0.8772 - val_accuracy: 0.7523\n",
      "Epoch 449/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.8419 - val_loss: 0.8892 - val_accuracy: 0.7505\n",
      "Epoch 450/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8442 - val_loss: 0.9070 - val_accuracy: 0.7687\n",
      "Epoch 451/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2778 - accuracy: 0.8424 - val_loss: 0.8871 - val_accuracy: 0.7632\n",
      "Epoch 452/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.8497 - val_loss: 0.8929 - val_accuracy: 0.7687\n",
      "Epoch 453/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8415 - val_loss: 0.8851 - val_accuracy: 0.7687\n",
      "Epoch 454/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8469 - val_loss: 0.9096 - val_accuracy: 0.7577\n",
      "Epoch 455/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2805 - accuracy: 0.8506 - val_loss: 0.8967 - val_accuracy: 0.7596\n",
      "Epoch 456/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.8510 - val_loss: 0.9020 - val_accuracy: 0.7559\n",
      "Epoch 457/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2789 - accuracy: 0.8469 - val_loss: 0.8984 - val_accuracy: 0.7596\n",
      "Epoch 458/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.8433 - val_loss: 0.9020 - val_accuracy: 0.7596\n",
      "Epoch 459/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8419 - val_loss: 0.8971 - val_accuracy: 0.7705\n",
      "Epoch 460/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.8460 - val_loss: 0.8962 - val_accuracy: 0.7668\n",
      "Epoch 461/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8446 - val_loss: 0.8709 - val_accuracy: 0.7687\n",
      "Epoch 462/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8497 - val_loss: 0.9103 - val_accuracy: 0.7559\n",
      "Epoch 463/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.8433 - val_loss: 0.9320 - val_accuracy: 0.7468\n",
      "Epoch 464/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8497 - val_loss: 0.8906 - val_accuracy: 0.7687\n",
      "Epoch 465/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.8474 - val_loss: 0.8879 - val_accuracy: 0.7632\n",
      "Epoch 466/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.8460 - val_loss: 0.8944 - val_accuracy: 0.7687\n",
      "Epoch 467/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2801 - accuracy: 0.8456 - val_loss: 0.9203 - val_accuracy: 0.7505\n",
      "Epoch 468/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.8451 - val_loss: 0.8964 - val_accuracy: 0.7596\n",
      "Epoch 469/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.8556 - val_loss: 0.9550 - val_accuracy: 0.7541\n",
      "Epoch 470/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8401 - val_loss: 0.9210 - val_accuracy: 0.7687\n",
      "Epoch 471/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8483 - val_loss: 0.9301 - val_accuracy: 0.7523\n",
      "Epoch 472/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.8478 - val_loss: 0.9050 - val_accuracy: 0.7650\n",
      "Epoch 473/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2797 - accuracy: 0.8492 - val_loss: 0.9351 - val_accuracy: 0.7596\n",
      "Epoch 474/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2816 - accuracy: 0.8497 - val_loss: 0.9005 - val_accuracy: 0.7668\n",
      "Epoch 475/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.8474 - val_loss: 0.9047 - val_accuracy: 0.7650\n",
      "Epoch 476/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.8492 - val_loss: 0.9125 - val_accuracy: 0.7614\n",
      "Epoch 477/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8446 - val_loss: 0.9106 - val_accuracy: 0.7577\n",
      "Epoch 478/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.8528 - val_loss: 0.8975 - val_accuracy: 0.7668\n",
      "Epoch 479/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2780 - accuracy: 0.8460 - val_loss: 0.9216 - val_accuracy: 0.7541\n",
      "Epoch 480/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.8460 - val_loss: 0.9241 - val_accuracy: 0.7650\n",
      "Epoch 481/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.8506 - val_loss: 0.9043 - val_accuracy: 0.7632\n",
      "Epoch 482/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2780 - accuracy: 0.8506 - val_loss: 0.9097 - val_accuracy: 0.7705\n",
      "Epoch 483/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8442 - val_loss: 0.9220 - val_accuracy: 0.7632\n",
      "Epoch 484/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2817 - accuracy: 0.8497 - val_loss: 0.9130 - val_accuracy: 0.7523\n",
      "Epoch 485/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8501 - val_loss: 0.9108 - val_accuracy: 0.7668\n",
      "Epoch 486/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8433 - val_loss: 0.8944 - val_accuracy: 0.7614\n",
      "Epoch 487/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.8465 - val_loss: 0.9014 - val_accuracy: 0.7614\n",
      "Epoch 488/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.8492 - val_loss: 0.9376 - val_accuracy: 0.7559\n",
      "Epoch 489/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.8456 - val_loss: 0.9357 - val_accuracy: 0.7614\n",
      "Epoch 490/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2780 - accuracy: 0.8456 - val_loss: 0.9259 - val_accuracy: 0.7541\n",
      "Epoch 491/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2780 - accuracy: 0.8433 - val_loss: 0.9141 - val_accuracy: 0.7577\n",
      "Epoch 492/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.8501 - val_loss: 0.9237 - val_accuracy: 0.7723\n",
      "Epoch 493/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.8492 - val_loss: 0.9273 - val_accuracy: 0.7632\n",
      "Epoch 494/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.8487 - val_loss: 0.9309 - val_accuracy: 0.7614\n",
      "Epoch 495/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.8474 - val_loss: 0.9190 - val_accuracy: 0.7541\n",
      "Epoch 496/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.8405 - val_loss: 0.9209 - val_accuracy: 0.7614\n",
      "Epoch 497/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.8469 - val_loss: 0.9418 - val_accuracy: 0.7523\n",
      "Epoch 498/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8442 - val_loss: 0.9312 - val_accuracy: 0.7541\n",
      "Epoch 499/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.8465 - val_loss: 0.9250 - val_accuracy: 0.7596\n",
      "Epoch 500/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8428 - val_loss: 0.9344 - val_accuracy: 0.7668\n",
      "Epoch 501/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2812 - accuracy: 0.8487 - val_loss: 0.9379 - val_accuracy: 0.7668\n",
      "Epoch 502/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8510 - val_loss: 0.9305 - val_accuracy: 0.7523\n",
      "Epoch 503/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.8451 - val_loss: 0.9340 - val_accuracy: 0.7596\n",
      "Epoch 504/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8569 - val_loss: 0.9467 - val_accuracy: 0.7596\n",
      "Epoch 505/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8506 - val_loss: 0.9415 - val_accuracy: 0.7596\n",
      "Epoch 506/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.8437 - val_loss: 0.9570 - val_accuracy: 0.7577\n",
      "Epoch 507/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.8474 - val_loss: 0.9378 - val_accuracy: 0.7614\n",
      "Epoch 508/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8510 - val_loss: 0.9574 - val_accuracy: 0.7505\n",
      "Epoch 509/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8446 - val_loss: 0.9452 - val_accuracy: 0.7577\n",
      "Epoch 510/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.8460 - val_loss: 0.9420 - val_accuracy: 0.7541\n",
      "Epoch 511/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.8487 - val_loss: 0.9390 - val_accuracy: 0.7851\n",
      "Epoch 512/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.8497 - val_loss: 0.9438 - val_accuracy: 0.7741\n",
      "Epoch 513/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8492 - val_loss: 0.9309 - val_accuracy: 0.7505\n",
      "Epoch 514/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.8483 - val_loss: 0.9206 - val_accuracy: 0.7596\n",
      "Epoch 515/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.8465 - val_loss: 0.9417 - val_accuracy: 0.7668\n",
      "Epoch 516/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8446 - val_loss: 0.9304 - val_accuracy: 0.7614\n",
      "Epoch 517/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8469 - val_loss: 0.9298 - val_accuracy: 0.7596\n",
      "Epoch 518/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8519 - val_loss: 0.9373 - val_accuracy: 0.7541\n",
      "Epoch 519/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.8419 - val_loss: 0.9311 - val_accuracy: 0.7505\n",
      "Epoch 520/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.8492 - val_loss: 0.9540 - val_accuracy: 0.7559\n",
      "Epoch 521/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8465 - val_loss: 0.9530 - val_accuracy: 0.7523\n",
      "Epoch 522/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.8474 - val_loss: 0.9643 - val_accuracy: 0.7650\n",
      "Epoch 523/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.8474 - val_loss: 0.9510 - val_accuracy: 0.7632\n",
      "Epoch 524/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2751 - accuracy: 0.8492 - val_loss: 0.9791 - val_accuracy: 0.7559\n",
      "Epoch 525/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8451 - val_loss: 0.9651 - val_accuracy: 0.7668\n",
      "Epoch 526/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2786 - accuracy: 0.8501 - val_loss: 0.9366 - val_accuracy: 0.7650\n",
      "Epoch 527/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.8460 - val_loss: 0.9384 - val_accuracy: 0.7523\n",
      "Epoch 528/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8497 - val_loss: 0.9578 - val_accuracy: 0.7596\n",
      "Epoch 529/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8465 - val_loss: 0.9402 - val_accuracy: 0.7650\n",
      "Epoch 530/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.8487 - val_loss: 0.9433 - val_accuracy: 0.7632\n",
      "Epoch 531/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8478 - val_loss: 0.9465 - val_accuracy: 0.7541\n",
      "Epoch 532/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2758 - accuracy: 0.8437 - val_loss: 0.9608 - val_accuracy: 0.7614\n",
      "Epoch 533/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.8497 - val_loss: 0.9339 - val_accuracy: 0.7541\n",
      "Epoch 534/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2750 - accuracy: 0.8460 - val_loss: 0.9302 - val_accuracy: 0.7632\n",
      "Epoch 535/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2785 - accuracy: 0.8515 - val_loss: 0.9316 - val_accuracy: 0.7596\n",
      "Epoch 536/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8483 - val_loss: 0.9482 - val_accuracy: 0.7596\n",
      "Epoch 537/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.8487 - val_loss: 0.9320 - val_accuracy: 0.7523\n",
      "Epoch 538/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.8506 - val_loss: 0.9345 - val_accuracy: 0.7760\n",
      "Epoch 539/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.8515 - val_loss: 0.9409 - val_accuracy: 0.7596\n",
      "Epoch 540/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.8487 - val_loss: 0.9625 - val_accuracy: 0.7523\n",
      "Epoch 541/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8501 - val_loss: 0.9578 - val_accuracy: 0.7705\n",
      "Epoch 542/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.8451 - val_loss: 0.9706 - val_accuracy: 0.7577\n",
      "Epoch 543/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8560 - val_loss: 0.9563 - val_accuracy: 0.7632\n",
      "Epoch 544/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2716 - accuracy: 0.8533 - val_loss: 0.9543 - val_accuracy: 0.7668\n",
      "Epoch 545/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8474 - val_loss: 0.9705 - val_accuracy: 0.7668\n",
      "Epoch 546/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.8469 - val_loss: 0.9668 - val_accuracy: 0.7741\n",
      "Epoch 547/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8465 - val_loss: 1.0028 - val_accuracy: 0.7650\n",
      "Epoch 548/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.8437 - val_loss: 0.9897 - val_accuracy: 0.7577\n",
      "Epoch 549/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8515 - val_loss: 0.9626 - val_accuracy: 0.7614\n",
      "Epoch 550/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8524 - val_loss: 0.9620 - val_accuracy: 0.7687\n",
      "Epoch 551/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.8515 - val_loss: 0.9534 - val_accuracy: 0.7614\n",
      "Epoch 552/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2731 - accuracy: 0.8506 - val_loss: 0.9578 - val_accuracy: 0.7541\n",
      "Epoch 553/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.8519 - val_loss: 0.9452 - val_accuracy: 0.7650\n",
      "Epoch 554/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.8533 - val_loss: 0.9789 - val_accuracy: 0.7541\n",
      "Epoch 555/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.8506 - val_loss: 0.9613 - val_accuracy: 0.7687\n",
      "Epoch 556/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.8501 - val_loss: 0.9716 - val_accuracy: 0.7577\n",
      "Epoch 557/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.8506 - val_loss: 0.9726 - val_accuracy: 0.7614\n",
      "Epoch 558/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.8465 - val_loss: 0.9696 - val_accuracy: 0.7632\n",
      "Epoch 559/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8492 - val_loss: 0.9745 - val_accuracy: 0.7596\n",
      "Epoch 560/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.8446 - val_loss: 0.9769 - val_accuracy: 0.7632\n",
      "Epoch 561/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.8474 - val_loss: 1.0174 - val_accuracy: 0.7668\n",
      "Epoch 562/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.8542 - val_loss: 0.9783 - val_accuracy: 0.7541\n",
      "Epoch 563/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2742 - accuracy: 0.8519 - val_loss: 0.9752 - val_accuracy: 0.7668\n",
      "Epoch 564/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.8519 - val_loss: 0.9997 - val_accuracy: 0.7541\n",
      "Epoch 565/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.8510 - val_loss: 0.9888 - val_accuracy: 0.7541\n",
      "Epoch 566/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2745 - accuracy: 0.8492 - val_loss: 0.9804 - val_accuracy: 0.7650\n",
      "Epoch 567/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8451 - val_loss: 0.9635 - val_accuracy: 0.7632\n",
      "Epoch 568/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8519 - val_loss: 0.9800 - val_accuracy: 0.7668\n",
      "Epoch 569/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.8456 - val_loss: 0.9905 - val_accuracy: 0.7577\n",
      "Epoch 570/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2750 - accuracy: 0.8506 - val_loss: 0.9694 - val_accuracy: 0.7705\n",
      "Epoch 571/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2764 - accuracy: 0.8446 - val_loss: 0.9859 - val_accuracy: 0.7486\n",
      "Epoch 572/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.8510 - val_loss: 0.9733 - val_accuracy: 0.7577\n",
      "Epoch 573/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.8547 - val_loss: 0.9619 - val_accuracy: 0.7632\n",
      "Epoch 574/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2736 - accuracy: 0.8456 - val_loss: 0.9871 - val_accuracy: 0.7577\n",
      "Epoch 575/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.8483 - val_loss: 1.0027 - val_accuracy: 0.7505\n",
      "Epoch 576/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8510 - val_loss: 0.9747 - val_accuracy: 0.7614\n",
      "Epoch 577/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8478 - val_loss: 1.0018 - val_accuracy: 0.7596\n",
      "Epoch 578/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.8501 - val_loss: 0.9763 - val_accuracy: 0.7705\n",
      "Epoch 579/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8510 - val_loss: 0.9558 - val_accuracy: 0.7687\n",
      "Epoch 580/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.8542 - val_loss: 0.9699 - val_accuracy: 0.7614\n",
      "Epoch 581/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8524 - val_loss: 0.9862 - val_accuracy: 0.7559\n",
      "Epoch 582/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8497 - val_loss: 0.9660 - val_accuracy: 0.7650\n",
      "Epoch 583/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8474 - val_loss: 0.9677 - val_accuracy: 0.7577\n",
      "Epoch 584/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2693 - accuracy: 0.8487 - val_loss: 1.0000 - val_accuracy: 0.7577\n",
      "Epoch 585/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8487 - val_loss: 0.9813 - val_accuracy: 0.7541\n",
      "Epoch 586/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8538 - val_loss: 0.9837 - val_accuracy: 0.7523\n",
      "Epoch 587/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.8456 - val_loss: 0.9825 - val_accuracy: 0.7614\n",
      "Epoch 588/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.8478 - val_loss: 0.9712 - val_accuracy: 0.7632\n",
      "Epoch 589/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8515 - val_loss: 0.9730 - val_accuracy: 0.7632\n",
      "Epoch 590/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8519 - val_loss: 0.9931 - val_accuracy: 0.7577\n",
      "Epoch 591/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8506 - val_loss: 0.9794 - val_accuracy: 0.7723\n",
      "Epoch 592/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.8506 - val_loss: 0.9896 - val_accuracy: 0.7523\n",
      "Epoch 593/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.8492 - val_loss: 0.9922 - val_accuracy: 0.7650\n",
      "Epoch 594/1000\n",
      "220/220 [==============================] - 1s 2ms/step - loss: 0.2769 - accuracy: 0.8524 - val_loss: 0.9950 - val_accuracy: 0.7632\n",
      "Epoch 595/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.8515 - val_loss: 0.9988 - val_accuracy: 0.7614\n",
      "Epoch 596/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.8524 - val_loss: 1.0136 - val_accuracy: 0.7596\n",
      "Epoch 597/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8547 - val_loss: 0.9885 - val_accuracy: 0.7632\n",
      "Epoch 598/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.8506 - val_loss: 0.9799 - val_accuracy: 0.7505\n",
      "Epoch 599/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8519 - val_loss: 0.9832 - val_accuracy: 0.7614\n",
      "Epoch 600/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8519 - val_loss: 1.0096 - val_accuracy: 0.7505\n",
      "Epoch 601/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.8469 - val_loss: 0.9831 - val_accuracy: 0.7577\n",
      "Epoch 602/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.8501 - val_loss: 0.9907 - val_accuracy: 0.7760\n",
      "Epoch 603/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8497 - val_loss: 1.0035 - val_accuracy: 0.7723\n",
      "Epoch 604/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8487 - val_loss: 0.9994 - val_accuracy: 0.7650\n",
      "Epoch 605/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.8515 - val_loss: 1.0021 - val_accuracy: 0.7486\n",
      "Epoch 606/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.8451 - val_loss: 1.0061 - val_accuracy: 0.7523\n",
      "Epoch 607/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.8510 - val_loss: 1.0048 - val_accuracy: 0.7559\n",
      "Epoch 608/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.8560 - val_loss: 1.0066 - val_accuracy: 0.7523\n",
      "Epoch 609/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8506 - val_loss: 1.0093 - val_accuracy: 0.7650\n",
      "Epoch 610/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8474 - val_loss: 1.0019 - val_accuracy: 0.7668\n",
      "Epoch 611/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.8497 - val_loss: 1.0145 - val_accuracy: 0.7486\n",
      "Epoch 612/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8497 - val_loss: 0.9979 - val_accuracy: 0.7614\n",
      "Epoch 613/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8506 - val_loss: 1.0014 - val_accuracy: 0.7541\n",
      "Epoch 614/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.8551 - val_loss: 0.9974 - val_accuracy: 0.7778\n",
      "Epoch 615/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8492 - val_loss: 1.0218 - val_accuracy: 0.7614\n",
      "Epoch 616/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8456 - val_loss: 1.0170 - val_accuracy: 0.7632\n",
      "Epoch 617/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8579 - val_loss: 1.0195 - val_accuracy: 0.7650\n",
      "Epoch 618/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.8401 - val_loss: 0.9987 - val_accuracy: 0.7668\n",
      "Epoch 619/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.8469 - val_loss: 1.0187 - val_accuracy: 0.7577\n",
      "Epoch 620/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.8465 - val_loss: 1.0136 - val_accuracy: 0.7577\n",
      "Epoch 621/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.8560 - val_loss: 1.0207 - val_accuracy: 0.7650\n",
      "Epoch 622/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.8515 - val_loss: 1.0251 - val_accuracy: 0.7541\n",
      "Epoch 623/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.8446 - val_loss: 1.0189 - val_accuracy: 0.7559\n",
      "Epoch 624/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8483 - val_loss: 1.0104 - val_accuracy: 0.7705\n",
      "Epoch 625/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8497 - val_loss: 1.0126 - val_accuracy: 0.7559\n",
      "Epoch 626/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8483 - val_loss: 1.0178 - val_accuracy: 0.7632\n",
      "Epoch 627/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2724 - accuracy: 0.8497 - val_loss: 1.0136 - val_accuracy: 0.7523\n",
      "Epoch 628/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2702 - accuracy: 0.8528 - val_loss: 1.0218 - val_accuracy: 0.7541\n",
      "Epoch 629/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8446 - val_loss: 1.0219 - val_accuracy: 0.7596\n",
      "Epoch 630/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.8497 - val_loss: 1.0294 - val_accuracy: 0.7577\n",
      "Epoch 631/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.8474 - val_loss: 1.0514 - val_accuracy: 0.7523\n",
      "Epoch 632/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.8583 - val_loss: 1.0458 - val_accuracy: 0.7577\n",
      "Epoch 633/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8483 - val_loss: 1.0429 - val_accuracy: 0.7559\n",
      "Epoch 634/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8538 - val_loss: 1.0598 - val_accuracy: 0.7650\n",
      "Epoch 635/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8551 - val_loss: 1.0356 - val_accuracy: 0.7632\n",
      "Epoch 636/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.8487 - val_loss: 1.0626 - val_accuracy: 0.7577\n",
      "Epoch 637/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2707 - accuracy: 0.8551 - val_loss: 1.0470 - val_accuracy: 0.7486\n",
      "Epoch 638/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2691 - accuracy: 0.8515 - val_loss: 1.0608 - val_accuracy: 0.7760\n",
      "Epoch 639/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8474 - val_loss: 1.0337 - val_accuracy: 0.7705\n",
      "Epoch 640/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8428 - val_loss: 1.0280 - val_accuracy: 0.7687\n",
      "Epoch 641/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8497 - val_loss: 1.0199 - val_accuracy: 0.7577\n",
      "Epoch 642/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8538 - val_loss: 1.0287 - val_accuracy: 0.7614\n",
      "Epoch 643/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.8492 - val_loss: 1.0436 - val_accuracy: 0.7614\n",
      "Epoch 644/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8524 - val_loss: 0.9944 - val_accuracy: 0.7705\n",
      "Epoch 645/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8519 - val_loss: 1.0340 - val_accuracy: 0.7541\n",
      "Epoch 646/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8497 - val_loss: 1.0381 - val_accuracy: 0.7614\n",
      "Epoch 647/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.8510 - val_loss: 1.0125 - val_accuracy: 0.7687\n",
      "Epoch 648/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8506 - val_loss: 1.0337 - val_accuracy: 0.7559\n",
      "Epoch 649/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.8524 - val_loss: 1.0383 - val_accuracy: 0.7450\n",
      "Epoch 650/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8515 - val_loss: 1.0540 - val_accuracy: 0.7577\n",
      "Epoch 651/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2696 - accuracy: 0.8524 - val_loss: 1.0466 - val_accuracy: 0.7596\n",
      "Epoch 652/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.8533 - val_loss: 1.0585 - val_accuracy: 0.7468\n",
      "Epoch 653/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.8524 - val_loss: 1.0787 - val_accuracy: 0.7596\n",
      "Epoch 654/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.8574 - val_loss: 1.0858 - val_accuracy: 0.7505\n",
      "Epoch 655/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8547 - val_loss: 1.0354 - val_accuracy: 0.7577\n",
      "Epoch 656/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.8533 - val_loss: 1.0626 - val_accuracy: 0.7632\n",
      "Epoch 657/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8538 - val_loss: 1.0557 - val_accuracy: 0.7541\n",
      "Epoch 658/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8501 - val_loss: 1.0614 - val_accuracy: 0.7596\n",
      "Epoch 659/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.8556 - val_loss: 1.0662 - val_accuracy: 0.7687\n",
      "Epoch 660/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.8497 - val_loss: 1.0480 - val_accuracy: 0.7650\n",
      "Epoch 661/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8497 - val_loss: 1.0662 - val_accuracy: 0.7559\n",
      "Epoch 662/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.8551 - val_loss: 1.0579 - val_accuracy: 0.7559\n",
      "Epoch 663/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8565 - val_loss: 1.0697 - val_accuracy: 0.7559\n",
      "Epoch 664/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.8487 - val_loss: 1.0565 - val_accuracy: 0.7577\n",
      "Epoch 665/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.8519 - val_loss: 1.0449 - val_accuracy: 0.7614\n",
      "Epoch 666/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2683 - accuracy: 0.8528 - val_loss: 1.0443 - val_accuracy: 0.7614\n",
      "Epoch 667/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.8501 - val_loss: 1.0574 - val_accuracy: 0.7577\n",
      "Epoch 668/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.8542 - val_loss: 1.0549 - val_accuracy: 0.7596\n",
      "Epoch 669/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.8556 - val_loss: 1.0466 - val_accuracy: 0.7650\n",
      "Epoch 670/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8442 - val_loss: 1.0516 - val_accuracy: 0.7559\n",
      "Epoch 671/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.8497 - val_loss: 1.0629 - val_accuracy: 0.7559\n",
      "Epoch 672/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8524 - val_loss: 1.0561 - val_accuracy: 0.7596\n",
      "Epoch 673/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8533 - val_loss: 1.0291 - val_accuracy: 0.7668\n",
      "Epoch 674/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.8538 - val_loss: 1.0328 - val_accuracy: 0.7650\n",
      "Epoch 675/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8528 - val_loss: 1.0509 - val_accuracy: 0.7577\n",
      "Epoch 676/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.8492 - val_loss: 1.0569 - val_accuracy: 0.7596\n",
      "Epoch 677/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.8510 - val_loss: 1.0573 - val_accuracy: 0.7486\n",
      "Epoch 678/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8519 - val_loss: 1.0744 - val_accuracy: 0.7559\n",
      "Epoch 679/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.8515 - val_loss: 1.0602 - val_accuracy: 0.7559\n",
      "Epoch 680/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.8492 - val_loss: 1.0630 - val_accuracy: 0.7559\n",
      "Epoch 681/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.8501 - val_loss: 1.0664 - val_accuracy: 0.7687\n",
      "Epoch 682/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.8574 - val_loss: 1.0660 - val_accuracy: 0.7596\n",
      "Epoch 683/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.8542 - val_loss: 1.0927 - val_accuracy: 0.7577\n",
      "Epoch 684/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8483 - val_loss: 1.1070 - val_accuracy: 0.7705\n",
      "Epoch 685/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8515 - val_loss: 1.0736 - val_accuracy: 0.7668\n",
      "Epoch 686/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8478 - val_loss: 1.1010 - val_accuracy: 0.7541\n",
      "Epoch 687/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.8524 - val_loss: 1.0733 - val_accuracy: 0.7596\n",
      "Epoch 688/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8551 - val_loss: 1.0979 - val_accuracy: 0.7760\n",
      "Epoch 689/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8542 - val_loss: 1.1193 - val_accuracy: 0.7505\n",
      "Epoch 690/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.8483 - val_loss: 1.1084 - val_accuracy: 0.7668\n",
      "Epoch 691/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.8515 - val_loss: 1.1008 - val_accuracy: 0.7523\n",
      "Epoch 692/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.8597 - val_loss: 1.1228 - val_accuracy: 0.7596\n",
      "Epoch 693/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8528 - val_loss: 1.1275 - val_accuracy: 0.7614\n",
      "Epoch 694/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.8551 - val_loss: 1.1318 - val_accuracy: 0.7541\n",
      "Epoch 695/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8501 - val_loss: 1.1167 - val_accuracy: 0.7632\n",
      "Epoch 696/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8574 - val_loss: 1.1196 - val_accuracy: 0.7614\n",
      "Epoch 697/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8538 - val_loss: 1.1394 - val_accuracy: 0.7486\n",
      "Epoch 698/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.8501 - val_loss: 1.1293 - val_accuracy: 0.7468\n",
      "Epoch 699/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.8515 - val_loss: 1.3258 - val_accuracy: 0.7523\n",
      "Epoch 700/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8556 - val_loss: 1.1389 - val_accuracy: 0.7577\n",
      "Epoch 701/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.8538 - val_loss: 1.1286 - val_accuracy: 0.7486\n",
      "Epoch 702/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.8501 - val_loss: 1.1313 - val_accuracy: 0.7559\n",
      "Epoch 703/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8492 - val_loss: 1.1367 - val_accuracy: 0.7614\n",
      "Epoch 704/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.8533 - val_loss: 1.1624 - val_accuracy: 0.7577\n",
      "Epoch 705/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.8560 - val_loss: 1.1532 - val_accuracy: 0.7650\n",
      "Epoch 706/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.8492 - val_loss: 1.1492 - val_accuracy: 0.7541\n",
      "Epoch 707/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8538 - val_loss: 1.1110 - val_accuracy: 0.7596\n",
      "Epoch 708/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8560 - val_loss: 1.1464 - val_accuracy: 0.7505\n",
      "Epoch 709/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.8515 - val_loss: 1.1317 - val_accuracy: 0.7541\n",
      "Epoch 710/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.8478 - val_loss: 1.1038 - val_accuracy: 0.7668\n",
      "Epoch 711/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8583 - val_loss: 1.0936 - val_accuracy: 0.7632\n",
      "Epoch 712/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.8565 - val_loss: 1.1268 - val_accuracy: 0.7632\n",
      "Epoch 713/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.8528 - val_loss: 1.1118 - val_accuracy: 0.7614\n",
      "Epoch 714/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.8538 - val_loss: 1.1168 - val_accuracy: 0.7650\n",
      "Epoch 715/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.8510 - val_loss: 1.1524 - val_accuracy: 0.7632\n",
      "Epoch 716/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8497 - val_loss: 1.1121 - val_accuracy: 0.7577\n",
      "Epoch 717/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8497 - val_loss: 1.1729 - val_accuracy: 0.7468\n",
      "Epoch 718/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8610 - val_loss: 1.1373 - val_accuracy: 0.7559\n",
      "Epoch 719/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.8506 - val_loss: 1.1241 - val_accuracy: 0.7577\n",
      "Epoch 720/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8487 - val_loss: 1.1242 - val_accuracy: 0.7596\n",
      "Epoch 721/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.8533 - val_loss: 1.1067 - val_accuracy: 0.7650\n",
      "Epoch 722/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.8487 - val_loss: 1.1390 - val_accuracy: 0.7596\n",
      "Epoch 723/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.8497 - val_loss: 1.1481 - val_accuracy: 0.7650\n",
      "Epoch 724/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.8542 - val_loss: 1.1350 - val_accuracy: 0.7614\n",
      "Epoch 725/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.8574 - val_loss: 1.1278 - val_accuracy: 0.7632\n",
      "Epoch 726/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.8515 - val_loss: 1.1284 - val_accuracy: 0.7687\n",
      "Epoch 727/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.8560 - val_loss: 1.1220 - val_accuracy: 0.7632\n",
      "Epoch 728/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8528 - val_loss: 1.1372 - val_accuracy: 0.7523\n",
      "Epoch 729/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.8497 - val_loss: 1.1335 - val_accuracy: 0.7505\n",
      "Epoch 730/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.8492 - val_loss: 1.1205 - val_accuracy: 0.7505\n",
      "Epoch 731/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8565 - val_loss: 1.1402 - val_accuracy: 0.7577\n",
      "Epoch 732/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8542 - val_loss: 1.1430 - val_accuracy: 0.7559\n",
      "Epoch 733/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2676 - accuracy: 0.8478 - val_loss: 1.1259 - val_accuracy: 0.7614\n",
      "Epoch 734/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.8465 - val_loss: 1.1542 - val_accuracy: 0.7559\n",
      "Epoch 735/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8515 - val_loss: 1.1471 - val_accuracy: 0.7632\n",
      "Epoch 736/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.8524 - val_loss: 1.1753 - val_accuracy: 0.7596\n",
      "Epoch 737/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8506 - val_loss: 1.1387 - val_accuracy: 0.7577\n",
      "Epoch 738/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8465 - val_loss: 1.1342 - val_accuracy: 0.7596\n",
      "Epoch 739/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.8483 - val_loss: 1.1207 - val_accuracy: 0.7650\n",
      "Epoch 740/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.8492 - val_loss: 1.1436 - val_accuracy: 0.7596\n",
      "Epoch 741/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2647 - accuracy: 0.8497 - val_loss: 1.1668 - val_accuracy: 0.7559\n",
      "Epoch 742/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.8538 - val_loss: 1.1440 - val_accuracy: 0.7596\n",
      "Epoch 743/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.8497 - val_loss: 1.1433 - val_accuracy: 0.7468\n",
      "Epoch 744/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.8515 - val_loss: 1.1529 - val_accuracy: 0.7559\n",
      "Epoch 745/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8524 - val_loss: 1.1483 - val_accuracy: 0.7723\n",
      "Epoch 746/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.8606 - val_loss: 1.1296 - val_accuracy: 0.7577\n",
      "Epoch 747/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.8551 - val_loss: 1.1227 - val_accuracy: 0.7687\n",
      "Epoch 748/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8533 - val_loss: 1.1558 - val_accuracy: 0.7577\n",
      "Epoch 749/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.8515 - val_loss: 1.1335 - val_accuracy: 0.7614\n",
      "Epoch 750/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8515 - val_loss: 1.1478 - val_accuracy: 0.7632\n",
      "Epoch 751/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8528 - val_loss: 1.1373 - val_accuracy: 0.7486\n",
      "Epoch 752/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8588 - val_loss: 1.1415 - val_accuracy: 0.7632\n",
      "Epoch 753/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.8560 - val_loss: 1.1760 - val_accuracy: 0.7559\n",
      "Epoch 754/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.8551 - val_loss: 1.1759 - val_accuracy: 0.7577\n",
      "Epoch 755/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.8492 - val_loss: 1.1676 - val_accuracy: 0.7541\n",
      "Epoch 756/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8533 - val_loss: 1.1439 - val_accuracy: 0.7559\n",
      "Epoch 757/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8497 - val_loss: 1.1744 - val_accuracy: 0.7523\n",
      "Epoch 758/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.8583 - val_loss: 1.1935 - val_accuracy: 0.7523\n",
      "Epoch 759/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.8592 - val_loss: 1.1841 - val_accuracy: 0.7577\n",
      "Epoch 760/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8483 - val_loss: 1.1743 - val_accuracy: 0.7523\n",
      "Epoch 761/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8519 - val_loss: 1.2276 - val_accuracy: 0.7596\n",
      "Epoch 762/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8487 - val_loss: 1.1990 - val_accuracy: 0.7650\n",
      "Epoch 763/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.8597 - val_loss: 1.1735 - val_accuracy: 0.7559\n",
      "Epoch 764/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.8560 - val_loss: 1.1999 - val_accuracy: 0.7632\n",
      "Epoch 765/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8538 - val_loss: 1.1856 - val_accuracy: 0.7523\n",
      "Epoch 766/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8510 - val_loss: 1.2095 - val_accuracy: 0.7596\n",
      "Epoch 767/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2676 - accuracy: 0.8542 - val_loss: 1.1761 - val_accuracy: 0.7577\n",
      "Epoch 768/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8547 - val_loss: 1.1788 - val_accuracy: 0.7632\n",
      "Epoch 769/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8469 - val_loss: 1.2284 - val_accuracy: 0.7668\n",
      "Epoch 770/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.8583 - val_loss: 1.2138 - val_accuracy: 0.7523\n",
      "Epoch 771/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8501 - val_loss: 1.2216 - val_accuracy: 0.7541\n",
      "Epoch 772/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8565 - val_loss: 1.1934 - val_accuracy: 0.7486\n",
      "Epoch 773/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.8528 - val_loss: 1.2145 - val_accuracy: 0.7668\n",
      "Epoch 774/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.8551 - val_loss: 1.1934 - val_accuracy: 0.7614\n",
      "Epoch 775/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.8579 - val_loss: 1.1885 - val_accuracy: 0.7614\n",
      "Epoch 776/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.8560 - val_loss: 1.2155 - val_accuracy: 0.7632\n",
      "Epoch 777/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.8565 - val_loss: 1.2373 - val_accuracy: 0.7650\n",
      "Epoch 778/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8533 - val_loss: 1.2160 - val_accuracy: 0.7687\n",
      "Epoch 779/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8547 - val_loss: 1.1827 - val_accuracy: 0.7632\n",
      "Epoch 780/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.8542 - val_loss: 1.2293 - val_accuracy: 0.7614\n",
      "Epoch 781/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8492 - val_loss: 1.1791 - val_accuracy: 0.7632\n",
      "Epoch 782/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8574 - val_loss: 1.1976 - val_accuracy: 0.7577\n",
      "Epoch 783/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8551 - val_loss: 1.1932 - val_accuracy: 0.7541\n",
      "Epoch 784/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.8551 - val_loss: 1.2326 - val_accuracy: 0.7541\n",
      "Epoch 785/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8592 - val_loss: 1.2412 - val_accuracy: 0.7523\n",
      "Epoch 786/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.8519 - val_loss: 1.2346 - val_accuracy: 0.7559\n",
      "Epoch 787/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.8510 - val_loss: 1.2507 - val_accuracy: 0.7541\n",
      "Epoch 788/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.8506 - val_loss: 1.2135 - val_accuracy: 0.7614\n",
      "Epoch 789/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.8528 - val_loss: 1.2182 - val_accuracy: 0.7559\n",
      "Epoch 790/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.8597 - val_loss: 1.2508 - val_accuracy: 0.7632\n",
      "Epoch 791/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.8510 - val_loss: 1.2222 - val_accuracy: 0.7577\n",
      "Epoch 792/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.8510 - val_loss: 1.1936 - val_accuracy: 0.7523\n",
      "Epoch 793/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.8487 - val_loss: 1.2303 - val_accuracy: 0.7541\n",
      "Epoch 794/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.8538 - val_loss: 1.2272 - val_accuracy: 0.7505\n",
      "Epoch 795/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.8506 - val_loss: 1.2424 - val_accuracy: 0.7486\n",
      "Epoch 796/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8538 - val_loss: 1.2184 - val_accuracy: 0.7614\n",
      "Epoch 797/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8510 - val_loss: 1.2280 - val_accuracy: 0.7632\n",
      "Epoch 798/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.8524 - val_loss: 1.2441 - val_accuracy: 0.7541\n",
      "Epoch 799/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8497 - val_loss: 1.2354 - val_accuracy: 0.7668\n",
      "Epoch 800/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8533 - val_loss: 1.2605 - val_accuracy: 0.7486\n",
      "Epoch 801/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8533 - val_loss: 1.2567 - val_accuracy: 0.7541\n",
      "Epoch 802/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8588 - val_loss: 1.2286 - val_accuracy: 0.7632\n",
      "Epoch 803/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.8556 - val_loss: 1.2209 - val_accuracy: 0.7596\n",
      "Epoch 804/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.8556 - val_loss: 1.2343 - val_accuracy: 0.7559\n",
      "Epoch 805/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8574 - val_loss: 1.2318 - val_accuracy: 0.7523\n",
      "Epoch 806/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.8551 - val_loss: 1.2634 - val_accuracy: 0.7650\n",
      "Epoch 807/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.8528 - val_loss: 1.2453 - val_accuracy: 0.7468\n",
      "Epoch 808/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2683 - accuracy: 0.8510 - val_loss: 1.2628 - val_accuracy: 0.7650\n",
      "Epoch 809/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.8624 - val_loss: 1.2296 - val_accuracy: 0.7668\n",
      "Epoch 810/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.8519 - val_loss: 1.2477 - val_accuracy: 0.7541\n",
      "Epoch 811/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.8533 - val_loss: 1.2593 - val_accuracy: 0.7632\n",
      "Epoch 812/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8528 - val_loss: 1.2493 - val_accuracy: 0.7596\n",
      "Epoch 813/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.8556 - val_loss: 1.2702 - val_accuracy: 0.7596\n",
      "Epoch 814/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.8506 - val_loss: 1.2634 - val_accuracy: 0.7559\n",
      "Epoch 815/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.8569 - val_loss: 1.2231 - val_accuracy: 0.7541\n",
      "Epoch 816/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.8528 - val_loss: 1.2686 - val_accuracy: 0.7632\n",
      "Epoch 817/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.8556 - val_loss: 1.2510 - val_accuracy: 0.7596\n",
      "Epoch 818/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.8569 - val_loss: 1.2530 - val_accuracy: 0.7541\n",
      "Epoch 819/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.8538 - val_loss: 1.2799 - val_accuracy: 0.7577\n",
      "Epoch 820/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.8510 - val_loss: 1.2698 - val_accuracy: 0.7468\n",
      "Epoch 821/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.8592 - val_loss: 1.2700 - val_accuracy: 0.7541\n",
      "Epoch 822/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.8574 - val_loss: 1.2740 - val_accuracy: 0.7505\n",
      "Epoch 823/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.8506 - val_loss: 1.2551 - val_accuracy: 0.7523\n",
      "Epoch 824/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8524 - val_loss: 1.2300 - val_accuracy: 0.7523\n",
      "Epoch 825/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8519 - val_loss: 1.2341 - val_accuracy: 0.7614\n",
      "Epoch 826/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2667 - accuracy: 0.8538 - val_loss: 1.2279 - val_accuracy: 0.7559\n",
      "Epoch 827/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8560 - val_loss: 1.2510 - val_accuracy: 0.7450\n",
      "Epoch 828/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8565 - val_loss: 1.3026 - val_accuracy: 0.7486\n",
      "Epoch 829/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.8579 - val_loss: 1.2463 - val_accuracy: 0.7632\n",
      "Epoch 830/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.8524 - val_loss: 1.2827 - val_accuracy: 0.7450\n",
      "Epoch 831/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.8519 - val_loss: 1.2387 - val_accuracy: 0.7668\n",
      "Epoch 832/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2636 - accuracy: 0.8579 - val_loss: 1.2615 - val_accuracy: 0.7559\n",
      "Epoch 833/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.8510 - val_loss: 1.2816 - val_accuracy: 0.7559\n",
      "Epoch 834/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.8610 - val_loss: 1.2734 - val_accuracy: 0.7486\n",
      "Epoch 835/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.8542 - val_loss: 1.3945 - val_accuracy: 0.7650\n",
      "Epoch 836/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.8483 - val_loss: 1.2757 - val_accuracy: 0.7577\n",
      "Epoch 837/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.8565 - val_loss: 1.3077 - val_accuracy: 0.7486\n",
      "Epoch 838/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.8519 - val_loss: 1.2748 - val_accuracy: 0.7577\n",
      "Epoch 839/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.8592 - val_loss: 1.2880 - val_accuracy: 0.7486\n",
      "Epoch 840/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8556 - val_loss: 1.2709 - val_accuracy: 0.7614\n",
      "Epoch 841/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.8569 - val_loss: 1.2506 - val_accuracy: 0.7468\n",
      "Epoch 842/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.8533 - val_loss: 1.3020 - val_accuracy: 0.7559\n",
      "Epoch 843/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.8569 - val_loss: 1.2576 - val_accuracy: 0.7577\n",
      "Epoch 844/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8533 - val_loss: 1.2752 - val_accuracy: 0.7596\n",
      "Epoch 845/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.8560 - val_loss: 1.2895 - val_accuracy: 0.7632\n",
      "Epoch 846/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.8469 - val_loss: 1.2969 - val_accuracy: 0.7687\n",
      "Epoch 847/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.8592 - val_loss: 1.2885 - val_accuracy: 0.7577\n",
      "Epoch 848/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.8524 - val_loss: 1.3095 - val_accuracy: 0.7596\n",
      "Epoch 849/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.8556 - val_loss: 1.2997 - val_accuracy: 0.7705\n",
      "Epoch 850/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.8542 - val_loss: 1.2659 - val_accuracy: 0.7650\n",
      "Epoch 851/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.8524 - val_loss: 1.3334 - val_accuracy: 0.7559\n",
      "Epoch 852/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2652 - accuracy: 0.8565 - val_loss: 1.2849 - val_accuracy: 0.7596\n",
      "Epoch 853/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.8538 - val_loss: 1.2860 - val_accuracy: 0.7596\n",
      "Epoch 854/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.8506 - val_loss: 1.3097 - val_accuracy: 0.7650\n",
      "Epoch 855/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.8569 - val_loss: 1.3209 - val_accuracy: 0.7541\n",
      "Epoch 856/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2610 - accuracy: 0.8565 - val_loss: 1.2931 - val_accuracy: 0.7541\n",
      "Epoch 857/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.8519 - val_loss: 1.3271 - val_accuracy: 0.7505\n",
      "Epoch 858/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8556 - val_loss: 1.2786 - val_accuracy: 0.7559\n",
      "Epoch 859/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.8524 - val_loss: 1.3513 - val_accuracy: 0.7523\n",
      "Epoch 860/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8615 - val_loss: 1.3684 - val_accuracy: 0.7577\n",
      "Epoch 861/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.8551 - val_loss: 1.3058 - val_accuracy: 0.7541\n",
      "Epoch 862/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2611 - accuracy: 0.8574 - val_loss: 1.3619 - val_accuracy: 0.7559\n",
      "Epoch 863/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.8492 - val_loss: 1.3641 - val_accuracy: 0.7596\n",
      "Epoch 864/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8556 - val_loss: 1.3268 - val_accuracy: 0.7577\n",
      "Epoch 865/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.8483 - val_loss: 1.3566 - val_accuracy: 0.7523\n",
      "Epoch 866/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.8551 - val_loss: 1.3944 - val_accuracy: 0.7505\n",
      "Epoch 867/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.8565 - val_loss: 1.3607 - val_accuracy: 0.7468\n",
      "Epoch 868/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.8556 - val_loss: 1.4096 - val_accuracy: 0.7486\n",
      "Epoch 869/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.8583 - val_loss: 1.3826 - val_accuracy: 0.7523\n",
      "Epoch 870/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.8542 - val_loss: 1.3851 - val_accuracy: 0.7650\n",
      "Epoch 871/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.8597 - val_loss: 1.3444 - val_accuracy: 0.7505\n",
      "Epoch 872/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8556 - val_loss: 1.3397 - val_accuracy: 0.7559\n",
      "Epoch 873/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8579 - val_loss: 1.3662 - val_accuracy: 0.7395\n",
      "Epoch 874/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8533 - val_loss: 1.3595 - val_accuracy: 0.7523\n",
      "Epoch 875/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.8569 - val_loss: 1.4563 - val_accuracy: 0.7468\n",
      "Epoch 876/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8565 - val_loss: 1.3957 - val_accuracy: 0.7596\n",
      "Epoch 877/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8551 - val_loss: 1.4188 - val_accuracy: 0.7505\n",
      "Epoch 878/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8579 - val_loss: 1.3895 - val_accuracy: 0.7614\n",
      "Epoch 879/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.8524 - val_loss: 1.4012 - val_accuracy: 0.7505\n",
      "Epoch 880/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.8515 - val_loss: 1.4132 - val_accuracy: 0.7541\n",
      "Epoch 881/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8601 - val_loss: 1.3581 - val_accuracy: 0.7486\n",
      "Epoch 882/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8533 - val_loss: 1.3569 - val_accuracy: 0.7614\n",
      "Epoch 883/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.8592 - val_loss: 1.3578 - val_accuracy: 0.7705\n",
      "Epoch 884/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8610 - val_loss: 1.4177 - val_accuracy: 0.7541\n",
      "Epoch 885/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.8565 - val_loss: 1.4606 - val_accuracy: 0.7541\n",
      "Epoch 886/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8569 - val_loss: 1.3903 - val_accuracy: 0.7577\n",
      "Epoch 887/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.8569 - val_loss: 1.4631 - val_accuracy: 0.7486\n",
      "Epoch 888/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.8560 - val_loss: 1.4867 - val_accuracy: 0.7632\n",
      "Epoch 889/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8524 - val_loss: 1.4573 - val_accuracy: 0.7577\n",
      "Epoch 890/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.8574 - val_loss: 1.4654 - val_accuracy: 0.7523\n",
      "Epoch 891/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.8542 - val_loss: 1.4853 - val_accuracy: 0.7541\n",
      "Epoch 892/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.8547 - val_loss: 1.4974 - val_accuracy: 0.7559\n",
      "Epoch 893/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.8515 - val_loss: 1.4949 - val_accuracy: 0.7577\n",
      "Epoch 894/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8510 - val_loss: 1.4747 - val_accuracy: 0.7486\n",
      "Epoch 895/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8538 - val_loss: 1.5039 - val_accuracy: 0.7650\n",
      "Epoch 896/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.8597 - val_loss: 1.4795 - val_accuracy: 0.7486\n",
      "Epoch 897/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.8551 - val_loss: 1.4522 - val_accuracy: 0.7650\n",
      "Epoch 898/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8515 - val_loss: 1.4903 - val_accuracy: 0.7687\n",
      "Epoch 899/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.8597 - val_loss: 1.4737 - val_accuracy: 0.7632\n",
      "Epoch 900/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8601 - val_loss: 1.4007 - val_accuracy: 0.7596\n",
      "Epoch 901/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.8565 - val_loss: 1.3958 - val_accuracy: 0.7650\n",
      "Epoch 902/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.8597 - val_loss: 1.3822 - val_accuracy: 0.7614\n",
      "Epoch 903/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8601 - val_loss: 1.4480 - val_accuracy: 0.7559\n",
      "Epoch 904/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.8583 - val_loss: 1.4640 - val_accuracy: 0.7559\n",
      "Epoch 905/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.8515 - val_loss: 1.4434 - val_accuracy: 0.7614\n",
      "Epoch 906/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.8515 - val_loss: 1.4563 - val_accuracy: 0.7486\n",
      "Epoch 907/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.8569 - val_loss: 1.4869 - val_accuracy: 0.7577\n",
      "Epoch 908/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8533 - val_loss: 1.4929 - val_accuracy: 0.7432\n",
      "Epoch 909/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8569 - val_loss: 1.5135 - val_accuracy: 0.7596\n",
      "Epoch 910/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.8556 - val_loss: 1.5085 - val_accuracy: 0.7468\n",
      "Epoch 911/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.8606 - val_loss: 1.4633 - val_accuracy: 0.7523\n",
      "Epoch 912/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8565 - val_loss: 1.5775 - val_accuracy: 0.7559\n",
      "Epoch 913/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.8533 - val_loss: 1.5084 - val_accuracy: 0.7577\n",
      "Epoch 914/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.8538 - val_loss: 1.5454 - val_accuracy: 0.7505\n",
      "Epoch 915/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8506 - val_loss: 1.5228 - val_accuracy: 0.7541\n",
      "Epoch 916/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.8597 - val_loss: 1.4904 - val_accuracy: 0.7596\n",
      "Epoch 917/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.8533 - val_loss: 1.5298 - val_accuracy: 0.7705\n",
      "Epoch 918/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.8538 - val_loss: 1.5540 - val_accuracy: 0.7577\n",
      "Epoch 919/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8565 - val_loss: 1.5650 - val_accuracy: 0.7632\n",
      "Epoch 920/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8569 - val_loss: 1.5375 - val_accuracy: 0.7541\n",
      "Epoch 921/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.8597 - val_loss: 1.5678 - val_accuracy: 0.7596\n",
      "Epoch 922/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8592 - val_loss: 1.5733 - val_accuracy: 0.7632\n",
      "Epoch 923/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.8565 - val_loss: 1.5363 - val_accuracy: 0.7486\n",
      "Epoch 924/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.8574 - val_loss: 1.5017 - val_accuracy: 0.7614\n",
      "Epoch 925/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.8601 - val_loss: 1.5241 - val_accuracy: 0.7596\n",
      "Epoch 926/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.8551 - val_loss: 1.5619 - val_accuracy: 0.7723\n",
      "Epoch 927/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8588 - val_loss: 1.5728 - val_accuracy: 0.7559\n",
      "Epoch 928/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8556 - val_loss: 1.5491 - val_accuracy: 0.7541\n",
      "Epoch 929/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.8560 - val_loss: 1.5902 - val_accuracy: 0.7505\n",
      "Epoch 930/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.8528 - val_loss: 1.5751 - val_accuracy: 0.7650\n",
      "Epoch 931/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8579 - val_loss: 1.5053 - val_accuracy: 0.7559\n",
      "Epoch 932/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8542 - val_loss: 1.5255 - val_accuracy: 0.7377\n",
      "Epoch 933/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2619 - accuracy: 0.8588 - val_loss: 1.5307 - val_accuracy: 0.7486\n",
      "Epoch 934/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8574 - val_loss: 1.5122 - val_accuracy: 0.7559\n",
      "Epoch 935/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.8560 - val_loss: 1.5738 - val_accuracy: 0.7632\n",
      "Epoch 936/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.8574 - val_loss: 1.5336 - val_accuracy: 0.7577\n",
      "Epoch 937/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.8483 - val_loss: 1.5558 - val_accuracy: 0.7632\n",
      "Epoch 938/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8538 - val_loss: 1.5403 - val_accuracy: 0.7705\n",
      "Epoch 939/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.8478 - val_loss: 1.6029 - val_accuracy: 0.7632\n",
      "Epoch 940/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.8574 - val_loss: 1.5529 - val_accuracy: 0.7614\n",
      "Epoch 941/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.8556 - val_loss: 1.5737 - val_accuracy: 0.7723\n",
      "Epoch 942/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.8560 - val_loss: 1.6889 - val_accuracy: 0.7577\n",
      "Epoch 943/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.8583 - val_loss: 1.6877 - val_accuracy: 0.7523\n",
      "Epoch 944/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.8560 - val_loss: 1.6506 - val_accuracy: 0.7632\n",
      "Epoch 945/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.8547 - val_loss: 1.6370 - val_accuracy: 0.7614\n",
      "Epoch 946/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.8592 - val_loss: 1.6083 - val_accuracy: 0.7541\n",
      "Epoch 947/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.8515 - val_loss: 1.6610 - val_accuracy: 0.7541\n",
      "Epoch 948/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8538 - val_loss: 1.6375 - val_accuracy: 0.7541\n",
      "Epoch 949/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.8556 - val_loss: 1.6298 - val_accuracy: 0.7523\n",
      "Epoch 950/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.8542 - val_loss: 1.6875 - val_accuracy: 0.7596\n",
      "Epoch 951/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.8647 - val_loss: 1.6505 - val_accuracy: 0.7614\n",
      "Epoch 952/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8528 - val_loss: 1.6851 - val_accuracy: 0.7614\n",
      "Epoch 953/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8556 - val_loss: 1.6748 - val_accuracy: 0.7523\n",
      "Epoch 954/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.8597 - val_loss: 1.6187 - val_accuracy: 0.7559\n",
      "Epoch 955/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2570 - accuracy: 0.8560 - val_loss: 1.6558 - val_accuracy: 0.7541\n",
      "Epoch 956/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.8565 - val_loss: 1.6248 - val_accuracy: 0.7559\n",
      "Epoch 957/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.8569 - val_loss: 1.6546 - val_accuracy: 0.7577\n",
      "Epoch 958/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2553 - accuracy: 0.8583 - val_loss: 1.6012 - val_accuracy: 0.7596\n",
      "Epoch 959/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.8569 - val_loss: 1.6622 - val_accuracy: 0.7596\n",
      "Epoch 960/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8560 - val_loss: 1.6101 - val_accuracy: 0.7486\n",
      "Epoch 961/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.8579 - val_loss: 1.6245 - val_accuracy: 0.7650\n",
      "Epoch 962/1000\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2578 - accuracy: 0.8574 - val_loss: 1.6419 - val_accuracy: 0.7596\n",
      "Epoch 963/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.8538 - val_loss: 1.6357 - val_accuracy: 0.7523\n",
      "Epoch 964/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.8629 - val_loss: 1.6752 - val_accuracy: 0.7505\n",
      "Epoch 965/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.8533 - val_loss: 1.6940 - val_accuracy: 0.7541\n",
      "Epoch 966/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8542 - val_loss: 1.6731 - val_accuracy: 0.7486\n",
      "Epoch 967/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8528 - val_loss: 1.7293 - val_accuracy: 0.7559\n",
      "Epoch 968/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.8624 - val_loss: 1.5662 - val_accuracy: 0.7541\n",
      "Epoch 969/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.8533 - val_loss: 1.6380 - val_accuracy: 0.7486\n",
      "Epoch 970/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.8528 - val_loss: 1.5984 - val_accuracy: 0.7486\n",
      "Epoch 971/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.8560 - val_loss: 1.6296 - val_accuracy: 0.7450\n",
      "Epoch 972/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.8565 - val_loss: 1.6394 - val_accuracy: 0.7450\n",
      "Epoch 973/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.8542 - val_loss: 1.5816 - val_accuracy: 0.7486\n",
      "Epoch 974/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.8565 - val_loss: 1.5660 - val_accuracy: 0.7596\n",
      "Epoch 975/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.8588 - val_loss: 1.5761 - val_accuracy: 0.7632\n",
      "Epoch 976/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.8588 - val_loss: 1.5854 - val_accuracy: 0.7505\n",
      "Epoch 977/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8551 - val_loss: 1.5746 - val_accuracy: 0.7596\n",
      "Epoch 978/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.8538 - val_loss: 1.5707 - val_accuracy: 0.7505\n",
      "Epoch 979/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.8569 - val_loss: 1.5969 - val_accuracy: 0.7632\n",
      "Epoch 980/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.8565 - val_loss: 1.6190 - val_accuracy: 0.7468\n",
      "Epoch 981/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.8588 - val_loss: 1.5871 - val_accuracy: 0.7577\n",
      "Epoch 982/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.8565 - val_loss: 1.5993 - val_accuracy: 0.7632\n",
      "Epoch 983/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.8601 - val_loss: 1.6182 - val_accuracy: 0.7577\n",
      "Epoch 984/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.8556 - val_loss: 1.6218 - val_accuracy: 0.7468\n",
      "Epoch 985/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8560 - val_loss: 1.6172 - val_accuracy: 0.7632\n",
      "Epoch 986/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.8560 - val_loss: 1.7293 - val_accuracy: 0.7559\n",
      "Epoch 987/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.8565 - val_loss: 1.6018 - val_accuracy: 0.7614\n",
      "Epoch 988/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.8551 - val_loss: 1.6561 - val_accuracy: 0.7596\n",
      "Epoch 989/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.8606 - val_loss: 1.6071 - val_accuracy: 0.7577\n",
      "Epoch 990/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.8565 - val_loss: 1.6688 - val_accuracy: 0.7541\n",
      "Epoch 991/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.8592 - val_loss: 1.6145 - val_accuracy: 0.7505\n",
      "Epoch 992/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8528 - val_loss: 1.6652 - val_accuracy: 0.7450\n",
      "Epoch 993/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.8565 - val_loss: 1.6547 - val_accuracy: 0.7486\n",
      "Epoch 994/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8597 - val_loss: 1.6297 - val_accuracy: 0.7432\n",
      "Epoch 995/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.8542 - val_loss: 1.5519 - val_accuracy: 0.7577\n",
      "Epoch 996/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.8601 - val_loss: 1.6041 - val_accuracy: 0.7468\n",
      "Epoch 997/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8597 - val_loss: 1.5949 - val_accuracy: 0.7577\n",
      "Epoch 998/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.8597 - val_loss: 1.5762 - val_accuracy: 0.7523\n",
      "Epoch 999/1000\n",
      "220/220 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.8565 - val_loss: 1.6010 - val_accuracy: 0.7614\n",
      "Epoch 1000/1000\n",
      "220/220 [==============================] - 1s 2ms/step - loss: 0.2575 - accuracy: 0.8574 - val_loss: 1.6502 - val_accuracy: 0.7450\n",
      "Training Accuracy: 0.8469387888908386\n",
      "Test Accuracy: 0.7448979616165161\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=1000, batch_size=10, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "_, train_accuracy = model.evaluate(X_train_scaled, y_train, verbose=0)\n",
    "_, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "print(f'Training Accuracy: {train_accuracy}')\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mosresdev4_1000epochs_train85acc.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model1 = load_model(r'C:\\Users\\rithv\\OneDrive\\Desktop\\cnn_rnn_models\\mosquito_resdev\\mosresdev4_1000epochs_train85acc.keras')  # Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in the original data: 99\n",
      "Number of features in the new data: 99\n"
     ]
    }
   ],
   "source": [
    "# Add missing columns with a default value of 0\n",
    "for col in df_encoded.columns:\n",
    "    if col not in additional_df_encoded:\n",
    "        additional_df_encoded[col] = 0\n",
    "\n",
    "# Drop any columns in additional_df_encoded that are not in df_encoded\n",
    "additional_df_encoded = additional_df_encoded[df_encoded.columns]\n",
    "\n",
    "# Verify the number of features\n",
    "print(\"Number of features in the original data:\", df_encoded.shape[1])\n",
    "print(\"Number of features in the new data:\", additional_df_encoded.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
